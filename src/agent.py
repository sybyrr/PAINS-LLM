"""
Agent module - ë©”ì¸ ì—ì´ì „íŠ¸ êµ¬í˜„

Function Callingì´ ê°€ëŠ¥í•œ OpenAI Agentë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.
ë…¼ë¬¸ Section 4.5 (LLM Orchestration and Analysis Generation)ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
1. ëŒ€í™” ê´€ë¦¬ (ë©”ëª¨ë¦¬)
2. ë„êµ¬ í˜¸ì¶œ (Function Calling)
3. ì‘ë‹µ ìƒì„± ë° í¬ë§·íŒ…
"""

import json
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, field

from langchain_openai import ChatOpenAI
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.memory import ConversationBufferWindowMemory
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

from .config import LLM_MODEL, OPENAI_API_KEY, TEMPERATURE
from .chain import run_analysis, ChainResult
from .tools import get_tools, generate_dashboard_json
from .utils import extract_teams_from_query, extract_date_from_query


# =============================================================================
# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
# =============================================================================

AGENT_SYSTEM_PROMPT = """ë‹¹ì‹ ì€ KBO í•œêµ­ í”„ë¡œì•¼êµ¬ ë°ì´í„° ë¶„ì„ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

## ì—­í• 
- ì‚¬ìš©ìì˜ ì•¼êµ¬ ê´€ë ¨ ì§ˆë¬¸ì— ì •í™•í•˜ê³  í†µì°°ë ¥ ìˆëŠ” ë‹µë³€ ì œê³µ
- íŒ€/ì„ ìˆ˜ ì„±ì  ë¶„ì„ ë° ì‹œê°í™”
- ì•¼êµ¬ í†µê³„ì™€ ê·œì¹™ì— ëŒ€í•œ ì„¤ëª…

## í•µì‹¬ ì›ì¹™

1. **ë°ì´í„° ê¸°ë°˜ ë¶„ì„**
   - ì œê³µëœ ë°ì´í„°ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„
   - ì¶”ì¸¡ì´ë‚˜ í—ˆêµ¬ ì •ë³´ ì œê³µ ê¸ˆì§€
   - ë°ì´í„° ì¶œì²˜ ëª…ì‹œ

2. **ì¤‘ë¦½ì  ê´€ì **
   - íŠ¹ì • íŒ€ì— ëŒ€í•œ í¸í–¥ ì—†ì´ ê°ê´€ì  ë¶„ì„
   - ê¸ì •ì /ë¶€ì •ì  ìš”ì†Œ ê· í˜•ìˆê²Œ ì œì‹œ

3. **ì‚¬ìš©ì ì¹œí™”ì  ì‘ë‹µ**
   - ì „ë¬¸ ìš©ì–´ ì‚¬ìš© ì‹œ ì„¤ëª… ì¶”ê°€
   - ë§ˆí¬ë‹¤ìš´ í‘œì™€ ëª©ë¡ í™œìš©
   - í•µì‹¬ ë‚´ìš© ë¨¼ì € ì œì‹œ

4. **ë„êµ¬ í™œìš© (Function Calling)**
   - ì‹œê°í™”ê°€ í•„ìš”í•˜ë©´ generate_dashboard_json í˜¸ì¶œ
   - íŒ€ ë¹„êµê°€ í•„ìš”í•˜ë©´ compare_teams í˜¸ì¶œ
   - ë„êµ¬ ì‚¬ìš© ì „ ì‚¬ìš©ìì—ê²Œ ì•ˆë‚´

## KBO íŒ€ ì •ë³´
- í•œí™” ì´ê¸€ìŠ¤ (Hanwha)
- LG íŠ¸ìœˆìŠ¤ (LG)  
- ì‚¼ì„± ë¼ì´ì˜¨ì¦ˆ (Samsung)
- ë‘ì‚° ë² ì–´ìŠ¤ (Doosan)
- ë¡¯ë° ìì´ì–¸ì¸  (Lotte)
- ê¸°ì•„ íƒ€ì´ê±°ì¦ˆ (KIA)
- NC ë‹¤ì´ë…¸ìŠ¤ (NC)
- SSG ëœë”ìŠ¤ (SSG)
- í‚¤ì›€ íˆì–´ë¡œì¦ˆ (Kiwoom)
- KT ìœ„ì¦ˆ (KT)

## ì‘ë‹µ í˜•ì‹
- ë¶„ì„ ê²°ê³¼ëŠ” ë§ˆí¬ë‹¤ìš´ í‘œ í™œìš©
- í•µì‹¬ ì¸ì‚¬ì´íŠ¸ë¥¼ **êµµì€ ê¸€ì”¨**ë¡œ ê°•ì¡°
- ê¸´ ì‘ë‹µì€ ì„¹ì…˜ìœ¼ë¡œ êµ¬ë¶„

ì§€ê¸ˆë¶€í„° ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
"""


# =============================================================================
# Agent ì‘ë‹µ í´ë˜ìŠ¤
# =============================================================================

@dataclass
class AgentResponse:
    """ì—ì´ì „íŠ¸ ì‘ë‹µ"""
    query: str                          # ì‚¬ìš©ì ì¿¼ë¦¬
    response: str                       # í…ìŠ¤íŠ¸ ì‘ë‹µ
    tool_calls: List[Dict] = field(default_factory=list)  # í˜¸ì¶œëœ ë„êµ¬
    dashboard: Optional[Dict] = None    # ìƒì„±ëœ ëŒ€ì‹œë³´ë“œ (ìˆëŠ” ê²½ìš°)
    context_used: Optional[Dict] = None # ì‚¬ìš©ëœ ì»¨í…ìŠ¤íŠ¸ ë°ì´í„°
    error: Optional[str] = None         # ì˜¤ë¥˜ ë©”ì‹œì§€ (ìˆëŠ” ê²½ìš°)
    # ê²€ìƒ‰ ê²°ê³¼ ì •ë³´
    retrieval_score: float = 0.0        # ê²€ìƒ‰ ìœ ì‚¬ë„ ì ìˆ˜
    retrieval_method: str = "none"      # ê²€ìƒ‰ ë°©ë²• (semantic/bm25/hybrid)
    retrieved_doc_info: Optional[Dict] = None  # ê²€ìƒ‰ëœ ë¬¸ì„œ ì •ë³´


# =============================================================================
# KBO Agent í´ë˜ìŠ¤
# =============================================================================

class KBOAgent:
    """
    KBO ì•¼êµ¬ ë¶„ì„ ì—ì´ì „íŠ¸
    
    Function Callingì„ ì§€ì›í•˜ëŠ” ëŒ€í™”í˜• ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.
    """
    
    def __init__(
        self, 
        model: str = None, 
        temperature: float = None,
        memory_window: int = 10
    ):
        """
        ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
        
        Args:
            model: ì‚¬ìš©í•  LLM ëª¨ë¸
            temperature: ëª¨ë¸ ì˜¨ë„
            memory_window: ëŒ€í™” ê¸°ì–µ ìœˆë„ìš° í¬ê¸°
        """
        self.model = model or LLM_MODEL
        self.temperature = temperature if temperature is not None else TEMPERATURE
        
        # LLM ì´ˆê¸°í™”
        self.llm = ChatOpenAI(
            model=self.model,
            temperature=self.temperature,
            api_key=OPENAI_API_KEY
        )
        
        # ë„êµ¬ ë¡œë“œ
        self.tools = get_tools()
        
        # ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
        self.memory = ConversationBufferWindowMemory(
            k=memory_window,
            memory_key="chat_history",
            return_messages=True
        )
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", AGENT_SYSTEM_PROMPT),
            MessagesPlaceholder(variable_name="chat_history"),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ])
        
        # ì—ì´ì „íŠ¸ ìƒì„±
        self.agent = create_openai_tools_agent(
            llm=self.llm,
            tools=self.tools,
            prompt=self.prompt
        )
        
        # ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸°
        self.agent_executor = AgentExecutor(
            agent=self.agent,
            tools=self.tools,
            memory=self.memory,
            verbose=True,
            handle_parsing_errors=True,
            max_iterations=5,
        )
    
    def chat(self, query: str, query_type: str = None) -> AgentResponse:
        """
        ì‚¬ìš©ì ì¿¼ë¦¬ì— ì‘ë‹µí•©ë‹ˆë‹¤.
        
        Args:
            query: ì‚¬ìš©ì ì¿¼ë¦¬
            query_type: ë¯¸ë¦¬ ê²°ì •ëœ ì¿¼ë¦¬ íƒ€ì… ("1", "2", "3" ë˜ëŠ” "general", "season_analysis", "match_analysis")
                       Noneì´ë©´ LLMìœ¼ë¡œ ìë™ ë¶„ë¥˜ (ê¸°ì¡´ ë°©ì‹)
        
        Returns:
            AgentResponse: ì—ì´ì „íŠ¸ ì‘ë‹µ
        """
        try:
            # 1. ë¶„ë¥˜ ìˆ˜í–‰
            if query_type:
                # ì‚¬ìš©ìê°€ ì„ ì§ˆë¬¸ì—ì„œ ì„ íƒí•œ íƒ€ì…ìœ¼ë¡œ ë¶„ë¥˜
                from .classifier import PreQuestionChoice, classify_by_user_choice
                
                # ì‚¬ìš©ì ì…ë ¥ì´ "1", "2", "3" ê°™ì€ ìˆ«ìì¸ ê²½ìš° ë¨¼ì € íŒŒì‹±
                if query_type in ["1", "2", "3"]:
                    parsed_type = PreQuestionChoice.parse_choice(query_type)
                    if parsed_type is None:
                        return AgentResponse(
                            query=query,
                            response=f"âŒ ì¸ì‹ ë¶ˆê°€ëŠ¥í•œ ì„ íƒì…ë‹ˆë‹¤: '{query_type}'",
                            error=f"ì¸ì‹ ë¶ˆê°€ëŠ¥í•œ ì„ íƒì…ë‹ˆë‹¤: '{query_type}'"
                        )
                    classification = classify_by_user_choice(query, query_type)
                else:
                    # ì´ë¯¸ íŒŒì‹±ëœ íƒ€ì…ì´ë©´ ì§ì ‘ ì‚¬ìš©
                    if query_type not in ["general", "season_analysis", "match_analysis"]:
                        return AgentResponse(
                            query=query,
                            response=f"âŒ ì¸ì‹ ë¶ˆê°€ëŠ¥í•œ ì§ˆë¬¸ íƒ€ì…ì…ë‹ˆë‹¤: '{query_type}'",
                            error=f"ì¸ì‹ ë¶ˆê°€ëŠ¥í•œ ì§ˆë¬¸ íƒ€ì…ì…ë‹ˆë‹¤: '{query_type}'"
                        )
                    # ì´ë¯¸ íŒŒì‹±ëœ íƒ€ì…ì„ ê¸°ë°˜ìœ¼ë¡œ ì§ì ‘ ë¶„ë¥˜ ê²°ê³¼ ìƒì„±
                    from .classifier import ClassificationResult, extract_teams_from_query, extract_date_from_query
                    teams = extract_teams_from_query(query)
                    team_names = [t[0] for t in teams]
                    date = extract_date_from_query(query) if query_type in ["match_analysis", "season_analysis"] else None
                    classification = ClassificationResult(
                        reasoning_steps=f"ì‚¬ìš©ì ì„ íƒ: {query_type}",
                        query_type=query_type,
                        teams=team_names,
                        date=date,
                        confidence=1.0
                    )
            else:
                # ê¸°ì¡´ ë°©ì‹: LLMìœ¼ë¡œ ìë™ ë¶„ë¥˜
                from .classifier import classify_query
                classification = classify_query(query)
            
            # 2. ë¶„ì„ ì²´ì¸ ì‹¤í–‰ (ë¶„ë¥˜ ê²°ê³¼ë¥¼ ì „ë‹¬)
            chain_result = run_analysis(query, classification)
            
            # 3. ì‘ë‹µ ê²°ì •
            # chainì—ì„œ ì´ë¯¸ ì™„ì„±ëœ ì‘ë‹µì„ ì‚¬ìš© (ë°ì´í„° ë¶„ì„ ì¿¼ë¦¬ì¸ ê²½ìš°)
            if chain_result.context and chain_result.query_type != "general":
                # ë¶„ì„ ì¿¼ë¦¬: chainì˜ ì‘ë‹µ ì§ì ‘ ì‚¬ìš© (ë°ì´í„° ì˜ë¦¼ ë°©ì§€)
                response_text = chain_result.response
            else:
                # ì¼ë°˜ ì§ˆë¬¸: ì—ì´ì „íŠ¸ ì§ì ‘ ì²˜ë¦¬
                result = self.agent_executor.invoke({"input": query})
                response_text = result.get("output", "")
            
            # 3. ëŒ€ì‹œë³´ë“œ í•„ìš” ì—¬ë¶€ í™•ì¸ ë° ìƒì„±
            dashboard = None
            tool_calls = []
            
            if chain_result.needs_dashboard and chain_result.teams:
                dashboard = self._create_dashboard(chain_result)
                tool_calls.append({
                    "tool": "generate_dashboard_json",
                    "args": {
                        "dashboard_type": chain_result.query_type,
                        "teams": chain_result.teams,
                    }
                })
            
            # 4. ê²€ìƒ‰ëœ ë¬¸ì„œ ì •ë³´ êµ¬ì„±
            retrieved_doc_info = None
            if chain_result.context:
                retrieved_doc_info = {
                    "type": chain_result.context.get("type"),
                    "teams": chain_result.context.get("teams", []),
                    "home_team": chain_result.context.get("home_team"),
                    "away_team": chain_result.context.get("away_team"),
                    "date": chain_result.context.get("date"),
                    "season": chain_result.context.get("season"),
                    "player_name": chain_result.context.get("data", {}).get("Name"),
                }
            
            return AgentResponse(
                query=query,
                response=response_text,
                tool_calls=tool_calls,
                dashboard=dashboard,
                context_used=chain_result.context,  # ì‹¤ì œ ì»¨í…ìŠ¤íŠ¸ ë°ì´í„° ì €ì¥
                error=None,
                retrieval_score=chain_result.retrieval_score,
                retrieval_method=chain_result.retrieval_method,
                retrieved_doc_info=retrieved_doc_info
            )
            
        except Exception as e:
            return AgentResponse(
                query=query,
                response=f"ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                error=str(e)
            )
    
    def _enhance_query_with_context(
        self, 
        query: str, 
        chain_result: ChainResult
    ) -> str:
        """
        ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ë¡œ ì¿¼ë¦¬ë¥¼ ê°•í™”í•©ë‹ˆë‹¤.
        
        Args:
            query: ì›ë³¸ ì¿¼ë¦¬
            chain_result: ì²´ì¸ ì‹¤í–‰ ê²°ê³¼
        
        Returns:
            str: ê°•í™”ëœ ì¿¼ë¦¬
        """
        context_summary = ""
        
        if chain_result.context:
            context_data = chain_result.context.get("data", {})
            context_summary = f"""

[ë¶„ì„ ë°ì´í„°]
- ë°ì´í„° ìœ í˜•: {chain_result.context.get('type')}
- íŒ€: {', '.join(chain_result.context.get('teams', []))}
- ì‹œì¦Œ/ë‚ ì§œ: {chain_result.context.get('season') or chain_result.context.get('date')}
- ê²€ìƒ‰ ì‹ ë¢°ë„: {chain_result.retrieval_score:.2%}

ë°ì´í„° ìš”ì•½:
{json.dumps(context_data, ensure_ascii=False, indent=2)[:2000]}
"""
        
        return f"{query}\n{context_summary}"
    
    def _create_dashboard(self, chain_result: ChainResult) -> Optional[Dict]:
        """
        ëŒ€ì‹œë³´ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            chain_result: ì²´ì¸ ì‹¤í–‰ ê²°ê³¼
        
        Returns:
            Optional[Dict]: ëŒ€ì‹œë³´ë“œ JSON
        """
        try:
            # ëŒ€ì‹œë³´ë“œ ìœ í˜• ê²°ì •
            if chain_result.query_type == "match_analysis":
                dashboard_type = "match_analysis"
            elif len(chain_result.teams) >= 2:
                dashboard_type = "team_comparison"
            else:
                dashboard_type = "season_analysis"
            
            # ì œëª© ìƒì„±
            teams_str = " vs ".join(chain_result.teams) if chain_result.teams else "KBO"
            title = f"{teams_str} ë¶„ì„ ëŒ€ì‹œë³´ë“œ"
            
            # season ê°’ ì¶”ì¶œ (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
            season = None
            if chain_result.context:
                season = chain_result.context.get("season")
                # ë‚ ì§œì—ì„œ ì—°ë„ ì¶”ì¶œ ì‹œë„
                if not season and chain_result.context.get("date"):
                    date_str = chain_result.context.get("date")
                    if date_str and len(date_str) >= 4:
                        season = date_str[:4]  # "2025-06-15" -> "2025"
            season = season or "2025"  # ìµœì¢… ê¸°ë³¸ê°’
            
            # ëŒ€ì‹œë³´ë“œ ìƒì„±
            dashboard = generate_dashboard_json.invoke({
                "dashboard_type": dashboard_type,
                "teams": chain_result.teams,
                "title": title,
                "date": chain_result.context.get("date") if chain_result.context else None,
                "season": season,
            })
            
            return dashboard
            
        except Exception as e:
            print(f"âš ï¸ ëŒ€ì‹œë³´ë“œ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def reset_memory(self):
        """ëŒ€í™” ë©”ëª¨ë¦¬ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        self.memory.clear()
        print("ğŸ’­ ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def get_conversation_history(self) -> List[Dict]:
        """
        ëŒ€í™” ê¸°ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Returns:
            List[Dict]: ëŒ€í™” ê¸°ë¡ ëª©ë¡
        """
        history = []
        for msg in self.memory.chat_memory.messages:
            if isinstance(msg, HumanMessage):
                history.append({"role": "user", "content": msg.content})
            elif isinstance(msg, AIMessage):
                history.append({"role": "assistant", "content": msg.content})
        return history


# =============================================================================
# ì‹±ê¸€í†¤ ë° í¸ì˜ í•¨ìˆ˜
# =============================================================================

_agent_instance: Optional[KBOAgent] = None


def get_agent() -> KBOAgent:
    """ì—ì´ì „íŠ¸ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _agent_instance
    if _agent_instance is None:
        _agent_instance = KBOAgent()
    return _agent_instance


def chat(query: str, query_type: str = None) -> AgentResponse:
    """
    ì±—ë´‡ê³¼ ëŒ€í™”í•˜ëŠ” í¸ì˜ í•¨ìˆ˜
    
    Args:
        query: ì‚¬ìš©ì ì¿¼ë¦¬
        query_type: ë¯¸ë¦¬ ê²°ì •ëœ ì¿¼ë¦¬ íƒ€ì… (ì„ ì§ˆë¬¸ì—ì„œ ë°›ì€ ì‚¬ìš©ì ì„ íƒ)
                   Noneì´ë©´ LLMìœ¼ë¡œ ìë™ ë¶„ë¥˜
    
    Returns:
        AgentResponse: ì—ì´ì „íŠ¸ ì‘ë‹µ
    
    Example:
        >>> from src.agent import chat
        >>> response = chat("í•œí™” ì˜¬ì‹œì¦Œ ì„±ì  ì–´ë•Œ?")
        >>> print(response.response)
        
        # ì‚¬ìš©ì ì„ íƒ ê¸°ë°˜ ë¶„ë¥˜
        >>> response = chat("í•œí™” ì„±ì ", "2")  # 2 = ì‹œì¦Œ ë¶„ì„
        >>> print(response.response)
    """
    agent = get_agent()
    return agent.chat(query, query_type)


# =============================================================================
# ëŒ€í™”í˜• CLI
# =============================================================================

def run_interactive_chat():
    """ëŒ€í™”í˜• CLI ì±—ë´‡ ì‹¤í–‰ - ì‚¬ìš©ì ì§ˆë¬¸ ìœ í˜• ì„ íƒ ê¸°ë°˜"""
    print("=" * 60)
    print("ğŸ¯ KBO ì•¼êµ¬ ë¶„ì„ ì±—ë´‡")
    print("=" * 60)
    print("ëª…ë ¹ì–´:")
    print("  /quit - ì¢…ë£Œ")
    print("  /reset - ëŒ€í™” ì´ˆê¸°í™”")
    print("  /history - ëŒ€í™” ê¸°ë¡ ë³´ê¸°")
    print("  /plot - ë§ˆì§€ë§‰ ë¶„ì„ ê²°ê³¼ ì‹œê°í™”")
    print("=" * 60)
    print("ğŸ’¡ íŒ: ì§ˆë¬¸ ëì— 'ì‹œê°í™”' ë˜ëŠ” 'plot'ì„ ì¶”ê°€í•˜ë©´ ì°¨íŠ¸ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
    print("=" * 60)
    
    agent = KBOAgent()
    last_context = None
    last_query_type = None
    last_teams = None
    
    while True:
        try:
            user_input = input("\nğŸ‘¤ You: ").strip()
            
            if not user_input:
                continue
            
            # ëª…ë ¹ì–´ ì²˜ë¦¬
            if user_input.lower() == "/quit":
                print("ğŸ‘‹ ì•ˆë…•íˆ ê°€ì„¸ìš”!")
                break
            elif user_input.lower() == "/reset":
                agent.reset_memory()
                last_context = None
                last_query_type = None
                last_teams = None
                continue
            elif user_input.lower() == "/history":
                history = agent.get_conversation_history()
                print("\nğŸ“œ ëŒ€í™” ê¸°ë¡:")
                for msg in history:
                    role = "ğŸ‘¤" if msg["role"] == "user" else "ğŸ¤–"
                    print(f"{role}: {msg['content'][:100]}...")
                continue
            elif user_input.lower() == "/plot":
                # ë§ˆì§€ë§‰ ë¶„ì„ ê²°ê³¼ ì‹œê°í™”
                if last_context and last_query_type:
                    from .chain import get_chain
                    chain = get_chain()
                    chain._show_visualization(
                        query_type=last_query_type,
                        teams=last_teams or [],
                        context=last_context
                    )
                else:
                    print("âš ï¸ ì‹œê°í™”í•  ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ê²½ê¸°ë‚˜ ì‹œì¦Œ ë¶„ì„ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”.")
                continue
            
            # "ì‹œê°í™”", "plot", "ì°¨íŠ¸" í‚¤ì›Œë“œ ì²´í¬
            show_plot = any(kw in user_input.lower() for kw in ['ì‹œê°í™”', 'plot', 'ì°¨íŠ¸', 'ê·¸ë˜í”„'])
            
            # =================================================================
            # ì§ˆë¬¸ ìœ í˜• ì„ íƒ ë‹¨ê³„: ì‚¬ìš©ìê°€ ì œì¼ ì²˜ìŒ ì„ íƒ
            # =================================================================
            from .classifier import generate_pre_question, PreQuestionChoice
            
            print(f"\n{generate_pre_question()}")
            
            # ì‚¬ìš©ì ì„ íƒ ì…ë ¥ë°›ê¸°
            while True:
                user_choice = input("\nâ¡ï¸ ì„ íƒ (1/2/3): ").strip()
                
                if not user_choice:
                    print("âš ï¸ ì„ íƒì„ ì…ë ¥í•´ì£¼ì„¸ìš” (1, 2, ë˜ëŠ” 3)")
                    continue
                
                # ìœ íš¨ì„± ê²€ì‚¬ (1, 2, 3ë§Œ ê°€ëŠ¥)
                if user_choice not in ["1", "2", "3"]:
                    print("âš ï¸ ì¸ì‹ ë¶ˆê°€ëŠ¥í•œ ì„ íƒì…ë‹ˆë‹¤. 1, 2, 3 ì¤‘ ì„ íƒí•´ì£¼ì„¸ìš”.")
                    continue
                
                # ìœ íš¨í•œ ì„ íƒì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš© (íŒŒì‹±ì€ agent.chatì—ì„œ)
                query_choice = user_choice
                break  # ìœ íš¨í•œ ì„ íƒ ë°›ìŒ
            
            # =================================================================
            # ë¶„ì„ ë‹¨ê³„: ì„ íƒëœ ìœ í˜•ì— ë”°ë¼ ì²˜ë¦¬
            # - 1 (ì¼ë°˜ ì§ˆë¬¸) â†’ APIë§Œ í˜¸ì¶œ
            # - 2 (ì„ ìˆ˜ ì‹œì¦Œ ì„±ì ) â†’ RAG ê²€ìƒ‰ + API
            # - 3 (íŠ¹ì • ê²½ê¸° ë¶„ì„) â†’ RAG ê²€ìƒ‰ + API
            # =================================================================
            print("\nğŸ¤– Assistant: ", end="", flush=True)
            response = agent.chat(user_input, query_choice)
            print(response.response)
            
            # ì»¨í…ìŠ¤íŠ¸ ì €ì¥
            if response.context_used and response.retrieved_doc_info:
                last_context = {
                    "type": response.retrieved_doc_info.get("type"),
                    "date": response.retrieved_doc_info.get("date"),
                    "home_team": response.retrieved_doc_info.get("home_team"),
                    "away_team": response.retrieved_doc_info.get("away_team"),
                    "teams": response.retrieved_doc_info.get("teams"),
                    "data": response.context_used.get("data", {}) if isinstance(response.context_used, dict) else {}
                }
                doc_type = response.retrieved_doc_info.get("type")
                if doc_type == "game":
                    last_query_type = "match_analysis"
                elif doc_type == "season":
                    last_query_type = "season_analysis"
                else:
                    last_query_type = doc_type
                last_teams = response.retrieved_doc_info.get("teams", [])
            
            # ê²€ìƒ‰ ì •ë³´ ì¶œë ¥ (ë¶„ì„ ì§ˆë¬¸ì¸ ê²½ìš°ë§Œ)
            if response.context_used and query_choice in ["2", "3"]:
                print(f"\nğŸ“‘ ê²€ìƒ‰ ì •ë³´ (ìœ ì‚¬ë„: {response.retrieval_score:.2%}, ë°©ë²•: {response.retrieval_method})")
                if response.retrieved_doc_info:
                    doc = response.retrieved_doc_info
                    info_parts = []
                    if doc.get('type'):
                        info_parts.append(f"íƒ€ì…: {doc['type']}")
                    if doc.get('teams'):
                        info_parts.append(f"íŒ€: {', '.join(doc['teams'])}")
                    if doc.get('date'):
                        info_parts.append(f"ë‚ ì§œ: {doc['date']}")
                    if doc.get('player_name'):
                        info_parts.append(f"ì„ ìˆ˜: {doc['player_name']}")
                    print(f"   {' | '.join(info_parts)}")
            
            # í‚¤ì›Œë“œë¡œ ì‹œê°í™” ìš”ì²­í•œ ê²½ìš°
            if show_plot and last_context and last_query_type:
                from .chain import get_chain
                chain = get_chain()
                chain._show_visualization(
                    query_type=last_query_type,
                    teams=last_teams or [],
                    context=last_context
                )
            
            # ëŒ€ì‹œë³´ë“œ ìƒì„± ì•Œë¦¼
            if response.dashboard:
                print("\nğŸ“Š ëŒ€ì‹œë³´ë“œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                print(f"   ìœ„ì ¯ ìˆ˜: {len(response.dashboard.get('widgets', []))}")
                print("   ğŸ’¡ '/plot' ëª…ë ¹ì–´ë¡œ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                print(f"   ìœ„ì ¯ ìˆ˜: {len(response.dashboard.get('widgets', []))}")
            
            # ì˜¤ë¥˜ ì²˜ë¦¬
            if response.error:
                print(f"\nâš ï¸ ì˜¤ë¥˜ ë°œìƒ: {response.error}")
        
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜: {e}")


# =============================================================================
# ë©”ì¸ ì§„ì…ì 
# =============================================================================

if __name__ == "__main__":
    run_interactive_chat()
