"""
Agent module - ë©”ì¸ ì—ì´ì „íŠ¸ êµ¬í˜„

Function Callingì´ ê°€ëŠ¥í•œ OpenAI Agentë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.
ë…¼ë¬¸ Section 4.5 (LLM Orchestration and Analysis Generation)ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
1. ëŒ€í™” ê´€ë¦¬ (ë©”ëª¨ë¦¬)
2. ë„êµ¬ í˜¸ì¶œ (Function Calling)
3. ì‘ë‹µ ìƒì„± ë° í¬ë§·íŒ…
"""

import json
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, field

from langchain_openai import ChatOpenAI
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.memory import ConversationBufferWindowMemory
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

from .config import LLM_MODEL, OPENAI_API_KEY, TEMPERATURE
from .chain import run_analysis, ChainResult
from .tools import get_tools, generate_dashboard_json


# =============================================================================
# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
# =============================================================================

AGENT_SYSTEM_PROMPT = """ë‹¹ì‹ ì€ KBO í•œêµ­ í”„ë¡œì•¼êµ¬ ë°ì´í„° ë¶„ì„ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

## ì—­í• 
- ì‚¬ìš©ìì˜ ì•¼êµ¬ ê´€ë ¨ ì§ˆë¬¸ì— ì •í™•í•˜ê³  í†µì°°ë ¥ ìˆëŠ” ë‹µë³€ ì œê³µ
- íŒ€/ì„ ìˆ˜ ì„±ì  ë¶„ì„ ë° ì‹œê°í™”
- ì•¼êµ¬ í†µê³„ì™€ ê·œì¹™ì— ëŒ€í•œ ì„¤ëª…

## í•µì‹¬ ì›ì¹™

1. **ë°ì´í„° ê¸°ë°˜ ë¶„ì„**
   - ì œê³µëœ ë°ì´í„°ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„
   - ì¶”ì¸¡ì´ë‚˜ í—ˆêµ¬ ì •ë³´ ì œê³µ ê¸ˆì§€
   - ë°ì´í„° ì¶œì²˜ ëª…ì‹œ

2. **ì¤‘ë¦½ì  ê´€ì **
   - íŠ¹ì • íŒ€ì— ëŒ€í•œ í¸í–¥ ì—†ì´ ê°ê´€ì  ë¶„ì„
   - ê¸ì •ì /ë¶€ì •ì  ìš”ì†Œ ê· í˜•ìˆê²Œ ì œì‹œ

3. **ì‚¬ìš©ì ì¹œí™”ì  ì‘ë‹µ**
   - ì „ë¬¸ ìš©ì–´ ì‚¬ìš© ì‹œ ì„¤ëª… ì¶”ê°€
   - ë§ˆí¬ë‹¤ìš´ í‘œì™€ ëª©ë¡ í™œìš©
   - í•µì‹¬ ë‚´ìš© ë¨¼ì € ì œì‹œ

4. **ë„êµ¬ í™œìš© (Function Calling)**
   - ì‹œê°í™”ê°€ í•„ìš”í•˜ë©´ generate_dashboard_json í˜¸ì¶œ
   - íŒ€ ë¹„êµê°€ í•„ìš”í•˜ë©´ compare_teams í˜¸ì¶œ
   - ë„êµ¬ ì‚¬ìš© ì „ ì‚¬ìš©ìì—ê²Œ ì•ˆë‚´

## KBO íŒ€ ì •ë³´
- í•œí™” ì´ê¸€ìŠ¤ (Hanwha)
- LG íŠ¸ìœˆìŠ¤ (LG)  
- ì‚¼ì„± ë¼ì´ì˜¨ì¦ˆ (Samsung)
- ë‘ì‚° ë² ì–´ìŠ¤ (Doosan)
- ë¡¯ë° ìì´ì–¸ì¸  (Lotte)
- ê¸°ì•„ íƒ€ì´ê±°ì¦ˆ (KIA)
- NC ë‹¤ì´ë…¸ìŠ¤ (NC)
- SSG ëœë”ìŠ¤ (SSG)
- í‚¤ì›€ íˆì–´ë¡œì¦ˆ (Kiwoom)
- KT ìœ„ì¦ˆ (KT)

## ì‘ë‹µ í˜•ì‹
- ë¶„ì„ ê²°ê³¼ëŠ” ë§ˆí¬ë‹¤ìš´ í‘œ í™œìš©
- í•µì‹¬ ì¸ì‚¬ì´íŠ¸ë¥¼ **êµµì€ ê¸€ì”¨**ë¡œ ê°•ì¡°
- ê¸´ ì‘ë‹µì€ ì„¹ì…˜ìœ¼ë¡œ êµ¬ë¶„

ì§€ê¸ˆë¶€í„° ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
"""


# =============================================================================
# Agent ì‘ë‹µ í´ë˜ìŠ¤
# =============================================================================

@dataclass
class AgentResponse:
    """ì—ì´ì „íŠ¸ ì‘ë‹µ"""
    query: str                          # ì‚¬ìš©ì ì¿¼ë¦¬
    response: str                       # í…ìŠ¤íŠ¸ ì‘ë‹µ
    tool_calls: List[Dict] = field(default_factory=list)  # í˜¸ì¶œëœ ë„êµ¬
    dashboard: Optional[Dict] = None    # ìƒì„±ëœ ëŒ€ì‹œë³´ë“œ (ìˆëŠ” ê²½ìš°)
    context_used: bool = False          # ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš© ì—¬ë¶€
    error: Optional[str] = None         # ì˜¤ë¥˜ ë©”ì‹œì§€ (ìˆëŠ” ê²½ìš°)


# =============================================================================
# KBO Agent í´ë˜ìŠ¤
# =============================================================================

class KBOAgent:
    """
    KBO ì•¼êµ¬ ë¶„ì„ ì—ì´ì „íŠ¸
    
    Function Callingì„ ì§€ì›í•˜ëŠ” ëŒ€í™”í˜• ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.
    """
    
    def __init__(
        self, 
        model: str = None, 
        temperature: float = None,
        memory_window: int = 10
    ):
        """
        ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
        
        Args:
            model: ì‚¬ìš©í•  LLM ëª¨ë¸
            temperature: ëª¨ë¸ ì˜¨ë„
            memory_window: ëŒ€í™” ê¸°ì–µ ìœˆë„ìš° í¬ê¸°
        """
        self.model = model or LLM_MODEL
        self.temperature = temperature if temperature is not None else TEMPERATURE
        
        # LLM ì´ˆê¸°í™”
        self.llm = ChatOpenAI(
            model=self.model,
            temperature=self.temperature,
            api_key=OPENAI_API_KEY
        )
        
        # ë„êµ¬ ë¡œë“œ
        self.tools = get_tools()
        
        # ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
        self.memory = ConversationBufferWindowMemory(
            k=memory_window,
            memory_key="chat_history",
            return_messages=True
        )
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", AGENT_SYSTEM_PROMPT),
            MessagesPlaceholder(variable_name="chat_history"),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ])
        
        # ì—ì´ì „íŠ¸ ìƒì„±
        self.agent = create_openai_tools_agent(
            llm=self.llm,
            tools=self.tools,
            prompt=self.prompt
        )
        
        # ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸°
        self.agent_executor = AgentExecutor(
            agent=self.agent,
            tools=self.tools,
            memory=self.memory,
            verbose=True,
            handle_parsing_errors=True,
            max_iterations=5,
        )
    
    def chat(self, query: str) -> AgentResponse:
        """
        ì‚¬ìš©ì ì¿¼ë¦¬ì— ì‘ë‹µí•©ë‹ˆë‹¤.
        
        Args:
            query: ì‚¬ìš©ì ì¿¼ë¦¬
        
        Returns:
            AgentResponse: ì—ì´ì „íŠ¸ ì‘ë‹µ
        """
        try:
            # 1. ë¶„ì„ ì²´ì¸ ì‹¤í–‰ (ë¶„ë¥˜ + ê²€ìƒ‰)
            chain_result = run_analysis(query)
            
            # 2. ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì—ì´ì „íŠ¸ í˜¸ì¶œ
            if chain_result.context:
                # ê²€ìƒ‰ëœ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš° ì»¨í…ìŠ¤íŠ¸ í¬í•¨
                enhanced_query = self._enhance_query_with_context(
                    query, chain_result
                )
                result = self.agent_executor.invoke({"input": enhanced_query})
            else:
                # ì¼ë°˜ ì§ˆë¬¸ì¸ ê²½ìš° ì§ì ‘ ì²˜ë¦¬
                result = self.agent_executor.invoke({"input": query})
            
            # 3. ì‘ë‹µ íŒŒì‹±
            response_text = result.get("output", "")
            
            # 4. ëŒ€ì‹œë³´ë“œ í•„ìš” ì—¬ë¶€ í™•ì¸ ë° ìƒì„±
            dashboard = None
            tool_calls = []
            
            if chain_result.needs_dashboard and chain_result.teams:
                dashboard = self._create_dashboard(chain_result)
                tool_calls.append({
                    "tool": "generate_dashboard_json",
                    "args": {
                        "dashboard_type": chain_result.query_type,
                        "teams": chain_result.teams,
                    }
                })
            
            return AgentResponse(
                query=query,
                response=response_text,
                tool_calls=tool_calls,
                dashboard=dashboard,
                context_used=chain_result.context is not None,
                error=None
            )
            
        except Exception as e:
            return AgentResponse(
                query=query,
                response=f"ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                error=str(e)
            )
    
    def _enhance_query_with_context(
        self, 
        query: str, 
        chain_result: ChainResult
    ) -> str:
        """
        ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ë¡œ ì¿¼ë¦¬ë¥¼ ê°•í™”í•©ë‹ˆë‹¤.
        
        Args:
            query: ì›ë³¸ ì¿¼ë¦¬
            chain_result: ì²´ì¸ ì‹¤í–‰ ê²°ê³¼
        
        Returns:
            str: ê°•í™”ëœ ì¿¼ë¦¬
        """
        context_summary = ""
        
        if chain_result.context:
            context_data = chain_result.context.get("data", {})
            context_summary = f"""

[ë¶„ì„ ë°ì´í„°]
- ë°ì´í„° ìœ í˜•: {chain_result.context.get('type')}
- íŒ€: {', '.join(chain_result.context.get('teams', []))}
- ì‹œì¦Œ/ë‚ ì§œ: {chain_result.context.get('season') or chain_result.context.get('date')}
- ê²€ìƒ‰ ì‹ ë¢°ë„: {chain_result.retrieval_score:.2%}

ë°ì´í„° ìš”ì•½:
{json.dumps(context_data, ensure_ascii=False, indent=2)[:2000]}
"""
        
        return f"{query}\n{context_summary}"
    
    def _create_dashboard(self, chain_result: ChainResult) -> Optional[Dict]:
        """
        ëŒ€ì‹œë³´ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            chain_result: ì²´ì¸ ì‹¤í–‰ ê²°ê³¼
        
        Returns:
            Optional[Dict]: ëŒ€ì‹œë³´ë“œ JSON
        """
        try:
            # ëŒ€ì‹œë³´ë“œ ìœ í˜• ê²°ì •
            if chain_result.query_type == "match_analysis":
                dashboard_type = "match_analysis"
            elif len(chain_result.teams) >= 2:
                dashboard_type = "team_comparison"
            else:
                dashboard_type = "season_analysis"
            
            # ì œëª© ìƒì„±
            teams_str = " vs ".join(chain_result.teams) if chain_result.teams else "KBO"
            title = f"{teams_str} ë¶„ì„ ëŒ€ì‹œë³´ë“œ"
            
            # ëŒ€ì‹œë³´ë“œ ìƒì„±
            dashboard = generate_dashboard_json.invoke({
                "dashboard_type": dashboard_type,
                "teams": chain_result.teams,
                "title": title,
                "date": chain_result.context.get("date") if chain_result.context else None,
                "season": chain_result.context.get("season", "2025") if chain_result.context else "2025",
            })
            
            return dashboard
            
        except Exception as e:
            print(f"âš ï¸ ëŒ€ì‹œë³´ë“œ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def reset_memory(self):
        """ëŒ€í™” ë©”ëª¨ë¦¬ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        self.memory.clear()
        print("ğŸ’­ ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def get_conversation_history(self) -> List[Dict]:
        """
        ëŒ€í™” ê¸°ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Returns:
            List[Dict]: ëŒ€í™” ê¸°ë¡ ëª©ë¡
        """
        history = []
        for msg in self.memory.chat_memory.messages:
            if isinstance(msg, HumanMessage):
                history.append({"role": "user", "content": msg.content})
            elif isinstance(msg, AIMessage):
                history.append({"role": "assistant", "content": msg.content})
        return history


# =============================================================================
# ì‹±ê¸€í†¤ ë° í¸ì˜ í•¨ìˆ˜
# =============================================================================

_agent_instance: Optional[KBOAgent] = None


def get_agent() -> KBOAgent:
    """ì—ì´ì „íŠ¸ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _agent_instance
    if _agent_instance is None:
        _agent_instance = KBOAgent()
    return _agent_instance


def chat(query: str) -> AgentResponse:
    """
    ì±—ë´‡ê³¼ ëŒ€í™”í•˜ëŠ” í¸ì˜ í•¨ìˆ˜
    
    Args:
        query: ì‚¬ìš©ì ì¿¼ë¦¬
    
    Returns:
        AgentResponse: ì—ì´ì „íŠ¸ ì‘ë‹µ
    
    Example:
        >>> from src.agent import chat
        >>> response = chat("í•œí™” ì˜¬ì‹œì¦Œ ì„±ì  ì–´ë•Œ?")
        >>> print(response.response)
    """
    agent = get_agent()
    return agent.chat(query)


# =============================================================================
# ëŒ€í™”í˜• CLI
# =============================================================================

def run_interactive_chat():
    """ëŒ€í™”í˜• CLI ì±—ë´‡ ì‹¤í–‰"""
    print("=" * 60)
    print("ğŸ¯ KBO ì•¼êµ¬ ë¶„ì„ ì±—ë´‡")
    print("=" * 60)
    print("ëª…ë ¹ì–´:")
    print("  /quit - ì¢…ë£Œ")
    print("  /reset - ëŒ€í™” ì´ˆê¸°í™”")
    print("  /history - ëŒ€í™” ê¸°ë¡ ë³´ê¸°")
    print("=" * 60)
    
    agent = KBOAgent()
    
    while True:
        try:
            user_input = input("\nğŸ‘¤ You: ").strip()
            
            if not user_input:
                continue
            
            # ëª…ë ¹ì–´ ì²˜ë¦¬
            if user_input.lower() == "/quit":
                print("ğŸ‘‹ ì•ˆë…•íˆ ê°€ì„¸ìš”!")
                break
            elif user_input.lower() == "/reset":
                agent.reset_memory()
                continue
            elif user_input.lower() == "/history":
                history = agent.get_conversation_history()
                print("\nğŸ“œ ëŒ€í™” ê¸°ë¡:")
                for msg in history:
                    role = "ğŸ‘¤" if msg["role"] == "user" else "ğŸ¤–"
                    print(f"{role}: {msg['content'][:100]}...")
                continue
            
            # ì±—ë´‡ ì‘ë‹µ
            print("\nğŸ¤– Assistant: ", end="")
            response = agent.chat(user_input)
            print(response.response)
            
            # ëŒ€ì‹œë³´ë“œ ìƒì„± ì•Œë¦¼
            if response.dashboard:
                print("\nğŸ“Š ëŒ€ì‹œë³´ë“œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                print(f"   ìœ„ì ¯ ìˆ˜: {len(response.dashboard.get('widgets', []))}")
            
            # ë„êµ¬ í˜¸ì¶œ ì •ë³´
            if response.tool_calls:
                print(f"\nğŸ”§ ì‚¬ìš©ëœ ë„êµ¬: {[t['tool'] for t in response.tool_calls]}")
                
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜: {e}")


# =============================================================================
# ë©”ì¸ ì§„ì…ì 
# =============================================================================

if __name__ == "__main__":
    run_interactive_chat()
