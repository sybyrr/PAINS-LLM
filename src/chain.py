"""
Chain module - ì •ê·œí™” + ë¼ìš°íŒ… + ê²€ìƒ‰ í†µí•© ì²´ì¸

ì‚¬ìš©ì ì¿¼ë¦¬ ì²˜ë¦¬ì˜ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.
ë…¼ë¬¸ Section 4.3 (User Query Processing) ë° Section 4.5 (LLM Orchestration)ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

íŒŒì´í”„ë¼ì¸:
1. ì¿¼ë¦¬ ì •ê·œí™” (íŒ€ëª…/ì„ ìˆ˜ëª… í‘œì¤€í™”)
2. ì˜ë„ ë¶„ë¥˜ (General, Season, Match)
3. ì¡°ê±´ë¶€ ê²€ìƒ‰ (ë¶„ë¥˜ ê²°ê³¼ì— ë”°ë¥¸ RAG)
4. LLM ì‘ë‹µ ìƒì„±
"""

import json
from typing import Dict, Optional, Tuple, Any
from dataclasses import dataclass

from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema import HumanMessage, SystemMessage

from .config import LLM_MODEL, OPENAI_API_KEY, TEMPERATURE
from .classifier import classify_query, ClassificationResult
from .retriever import retrieve_for_query
from .utils import extract_teams_from_query, normalize_team_name


# =============================================================================
# ì‘ë‹µ ìŠ¤í‚¤ë§ˆ
# =============================================================================

@dataclass
class ChainResult:
    """ì²´ì¸ ì‹¤í–‰ ê²°ê³¼"""
    query: str                          # ì›ë³¸ ì¿¼ë¦¬
    query_type: str                     # ë¶„ë¥˜ëœ ì¿¼ë¦¬ ìœ í˜•
    teams: list                         # ì¶”ì¶œëœ íŒ€ ëª©ë¡
    context: Optional[Dict]             # ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ (ìˆëŠ” ê²½ìš°)
    retrieval_score: float              # ê²€ìƒ‰ ì‹ ë¢°ë„
    retrieval_method: str               # ì‚¬ìš©ëœ ê²€ìƒ‰ ë°©ë²•
    response: str                       # LLM ìƒì„± ì‘ë‹µ
    needs_dashboard: bool               # ëŒ€ì‹œë³´ë“œ ìƒì„± í•„ìš” ì—¬ë¶€
    validation_passed: bool             # LLM-as-Judge ê²€ì¦ í†µê³¼ ì—¬ë¶€


# =============================================================================
# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜
# =============================================================================

SYSTEM_PROMPT_GENERAL = """ë‹¹ì‹ ì€ KBO í•œêµ­ í”„ë¡œì•¼êµ¬ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì—­í• :
- ì•¼êµ¬ í†µê³„, ê·œì¹™, ìš©ì–´ì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µë³€
- ë¶„ì„ ë°©ë²•ë¡  ì„¤ëª…
- ì¼ë°˜ì ì¸ ì•¼êµ¬ ì§€ì‹ ì œê³µ

ì§€ì¹¨:
- ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´ë§Œ ì œê³µí•˜ì„¸ìš”
- ë¶ˆí™•ì‹¤í•œ ê²½ìš° ëª…ì‹œí•˜ì„¸ìš”
- í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”
"""

SYSTEM_PROMPT_ANALYSIS = """ë‹¹ì‹ ì€ KBO í•œêµ­ í”„ë¡œì•¼êµ¬ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì—­í• :
- ì œê³µëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•œ ë¶„ì„ ì œê³µ
- í†µê³„ì  ì¸ì‚¬ì´íŠ¸ ë„ì¶œ
- íŒ€/ì„ ìˆ˜ ì„±ê³¼ í‰ê°€

## ì¤‘ìš” ì§€ì¹¨ (LLM-as-Judge)

1. **ë°ì´í„° ê²€ì¦ ìš°ì„ **: ë¶„ì„ ì „ ë°˜ë“œì‹œ ì œê³µëœ ë°ì´í„°ê°€ ìš”ì²­ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
   - ìš”ì²­ëœ íŒ€ê³¼ ë°ì´í„°ì˜ íŒ€ì´ ì¼ì¹˜í•˜ëŠ”ê°€?
   - ìš”ì²­ëœ ê¸°ê°„(ì‹œì¦Œ/ê²½ê¸° ë‚ ì§œ)ì´ ë°ì´í„°ì™€ ì¼ì¹˜í•˜ëŠ”ê°€?

2. **ë¶ˆì¼ì¹˜ ì²˜ë¦¬**:
   - ì™„ì „ ì¼ì¹˜: ë¶„ì„ ì§„í–‰
   - ë¶€ë¶„ ì¼ì¹˜ (íŒ€ì€ ë§ì§€ë§Œ ê¸°ê°„ ë¶ˆì¼ì¹˜): ì‚¬ìš©ìì—ê²Œ ì•Œë¦¬ê³  ê°€ìš© ë°ì´í„°ë¡œ ë¶„ì„
   - íŒ€ ë¶ˆì¼ì¹˜: ë¶„ì„ ê±°ë¶€, ì˜¬ë°”ë¥¸ ë°ì´í„° ìš”ì²­ ì•ˆë‚´

3. **ì‘ë‹µ í˜•ì‹**:
   - ë§ˆí¬ë‹¤ìš´ í‘œë¥¼ í™œìš©í•œ ëª…í™•í•œ ë°ì´í„° í‘œì‹œ
   - í•µì‹¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ë¨¼ì €, ìƒì„¸ ë¶„ì„ì€ ë’¤ì—
   - ìˆ˜ì¹˜ëŠ” ë°˜ë“œì‹œ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ

4. **ì‹œê°í™” í•„ìš”ì„± íŒë‹¨**:
   - ë°ì´í„°ê°€ í’ë¶€í•˜ê³  ë¹„êµ ë¶„ì„ì´ í•„ìš”í•˜ë©´ ëŒ€ì‹œë³´ë“œ ì¶”ì²œ
   - ë‹¨ìˆœ ì§ˆë¬¸ì´ë‚˜ ë°ì´í„° ë¶€ì¡±ì‹œ í…ìŠ¤íŠ¸ ë‹µë³€ìœ¼ë¡œ ì¶©ë¶„
"""

DATA_VALIDATION_PROMPT = """## ë°ì´í„° ê²€ì¦

ì‚¬ìš©ì ìš”ì²­:
- íŒ€: {requested_teams}
- ìœ í˜•: {query_type}
- ë‚ ì§œ: {requested_date}

ì œê³µëœ ë°ì´í„°:
- ë°ì´í„° íŒ€: {data_teams}
- ë°ì´í„° ìœ í˜•: {data_type}
- ë°ì´í„° ë‚ ì§œ/ì‹œì¦Œ: {data_period}

ê²€ì¦ ê²°ê³¼ë¥¼ íŒë‹¨í•˜ê³ , ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ ì‚¬ìš©ìì—ê²Œ ëª…í™•íˆ ì•Œë ¤ì£¼ì„¸ìš”.
"""


# =============================================================================
# LLM ì‘ë‹µ ìƒì„±
# =============================================================================

class KBOAnalysisChain:
    """
    KBO ë¶„ì„ ì²´ì¸
    
    ì •ê·œí™” â†’ ë¶„ë¥˜ â†’ ê²€ìƒ‰ â†’ ì‘ë‹µ ìƒì„±ì˜ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, model: str = None, temperature: float = None):
        """
        ì²´ì¸ ì´ˆê¸°í™”
        
        Args:
            model: ì‚¬ìš©í•  LLM ëª¨ë¸
            temperature: ëª¨ë¸ ì˜¨ë„
        """
        self.model = model or LLM_MODEL
        self.temperature = temperature if temperature is not None else TEMPERATURE
        
        self.llm = ChatOpenAI(
            model=self.model,
            temperature=self.temperature,
            api_key=OPENAI_API_KEY
        )
    
    def _normalize_query(self, query: str) -> Tuple[str, list]:
        """
        ì¿¼ë¦¬ì—ì„œ íŒ€ëª…ì„ ì •ê·œí™”í•©ë‹ˆë‹¤.
        
        Args:
            query: ì›ë³¸ ì¿¼ë¦¬
        
        Returns:
            Tuple[str, list]: (ì •ê·œí™”ëœ ì¿¼ë¦¬, ì¶”ì¶œëœ íŒ€ ëª©ë¡)
        """
        teams = extract_teams_from_query(query)
        normalized_teams = [t[0] for t in teams]  # (íŒ€ëª…, ì ìˆ˜)ì—ì„œ íŒ€ëª…ë§Œ
        
        return query, normalized_teams
    
    def _validate_data_match(
        self,
        classification: ClassificationResult,
        context: Dict
    ) -> Tuple[bool, str]:
        """
        ê²€ìƒ‰ëœ ë°ì´í„°ê°€ ìš”ì²­ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ ê²€ì¦í•©ë‹ˆë‹¤.
        
        ë…¼ë¬¸ Section 4.5.2 (LLM-as-a-judge) êµ¬í˜„
        
        Args:
            classification: ë¶„ë¥˜ ê²°ê³¼
            context: ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸
        
        Returns:
            Tuple[bool, str]: (ê²€ì¦ í†µê³¼ ì—¬ë¶€, ê²€ì¦ ë©”ì‹œì§€)
        """
        if not context:
            return False, "ê²€ìƒ‰ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        requested_teams = set(classification.teams)
        data_teams = set(context.get("teams", []))
        
        # íŒ€ ì¼ì¹˜ ê²€ì‚¬
        if requested_teams and data_teams:
            team_overlap = requested_teams & data_teams
            if not team_overlap:
                return False, f"ìš”ì²­í•˜ì‹  íŒ€({', '.join(requested_teams)})ì˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²€ìƒ‰ëœ ë°ì´í„°: {', '.join(data_teams)}"
        
        # ë¶€ë¶„ ì¼ì¹˜ (ê²½ê³ ì™€ í•¨ê»˜ ì§„í–‰)
        if requested_teams and data_teams and requested_teams != team_overlap:
            missing = requested_teams - team_overlap
            return True, f"ì¼ë¶€ íŒ€({', '.join(missing)}) ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê°€ìš©í•œ ë°ì´í„°ë¡œ ë¶„ì„í•©ë‹ˆë‹¤."
        
        return True, "ë°ì´í„° ê²€ì¦ ì™„ë£Œ"
    
    def _generate_response(
        self,
        query: str,
        query_type: str,
        context: Optional[Dict],
        validation_message: str
    ) -> Tuple[str, bool]:
        """
        LLMì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            query: ì‚¬ìš©ì ì¿¼ë¦¬
            query_type: ì¿¼ë¦¬ ìœ í˜•
            context: ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸
            validation_message: ë°ì´í„° ê²€ì¦ ë©”ì‹œì§€
        
        Returns:
            Tuple[str, bool]: (ì‘ë‹µ í…ìŠ¤íŠ¸, ëŒ€ì‹œë³´ë“œ í•„ìš” ì—¬ë¶€)
        """
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„ íƒ
        if query_type == "general":
            system_prompt = SYSTEM_PROMPT_GENERAL
        else:
            system_prompt = SYSTEM_PROMPT_ANALYSIS
        
        # ë©”ì‹œì§€ êµ¬ì„±
        messages = [SystemMessage(content=system_prompt)]
        
        # ì»¨í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ê²½ìš° ë°ì´í„° í¬í•¨
        if context and query_type != "general":
            context_str = json.dumps(context, ensure_ascii=False, indent=2)
            
            user_content = f"""## ì‚¬ìš©ì ì§ˆë¬¸
{query}

## ë°ì´í„° ê²€ì¦ ìƒíƒœ
{validation_message}

## ë¶„ì„ ë°ì´í„°
```json
{context_str}
```

ìœ„ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”. 
ë°ì´í„°ê°€ ìš”ì²­ê³¼ ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ ê·¸ ì‚¬ì‹¤ì„ ë¨¼ì € ì•Œë ¤ì£¼ì„¸ìš”.
ëŒ€ì‹œë³´ë“œ(ì‹œê°í™”)ê°€ ìœ ìš©í•  ê²ƒ ê°™ìœ¼ë©´ ë§ˆì§€ë§‰ì— "[ëŒ€ì‹œë³´ë“œ ì¶”ì²œ]"ì„ í¬í•¨í•´ì£¼ì„¸ìš”.
"""
        else:
            user_content = f"""## ì‚¬ìš©ì ì§ˆë¬¸
{query}

ì¼ë°˜ì ì¸ ì•¼êµ¬ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
"""
        
        messages.append(HumanMessage(content=user_content))
        
        # LLM í˜¸ì¶œ
        response = self.llm.invoke(messages)
        response_text = response.content
        
        # ëŒ€ì‹œë³´ë“œ í•„ìš” ì—¬ë¶€ íŒë‹¨
        needs_dashboard = "[ëŒ€ì‹œë³´ë“œ ì¶”ì²œ]" in response_text
        
        # ëŒ€ì‹œë³´ë“œ íƒœê·¸ ì œê±°
        response_text = response_text.replace("[ëŒ€ì‹œë³´ë“œ ì¶”ì²œ]", "").strip()
        
        return response_text, needs_dashboard
    
    def run(self, query: str) -> ChainResult:
        """
        ì „ì²´ ì²´ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
        
        Args:
            query: ì‚¬ìš©ì ì¿¼ë¦¬
        
        Returns:
            ChainResult: ì²´ì¸ ì‹¤í–‰ ê²°ê³¼
        """
        print(f"\n{'='*60}")
        print(f"ğŸ¯ ì¿¼ë¦¬: {query}")
        print(f"{'='*60}")
        
        # 1. ì •ê·œí™”
        _, normalized_teams = self._normalize_query(query)
        print(f"ğŸ“ ì •ê·œí™”ëœ íŒ€: {normalized_teams}")
        
        # 2. ë¶„ë¥˜
        classification = classify_query(query)
        print(f"ğŸ·ï¸ ë¶„ë¥˜: {classification.query_type} (ì‹ ë¢°ë„: {classification.confidence:.2f})")
        print(f"ğŸ“… ë‚ ì§œ: {classification.date}")
        
        # íŒ€ ì •ë³´ ë³‘í•© (ë¶„ë¥˜ê¸° + ì •ê·œí™”)
        all_teams = list(set(normalized_teams + classification.teams))
        
        # 3. ê²€ìƒ‰ (ë¶„ì„ ì¿¼ë¦¬ì¸ ê²½ìš°ë§Œ)
        context = None
        retrieval_score = 0.0
        retrieval_method = "none"
        validation_passed = True
        validation_message = ""
        
        if classification.query_type != "general":
            context, retrieval_score, retrieval_method = retrieve_for_query(
                query=query,
                query_type=classification.query_type,
                teams=all_teams,
                date=classification.date
            )
            
            print(f"ğŸ” ê²€ìƒ‰ ê²°ê³¼: {retrieval_method} (ì ìˆ˜: {retrieval_score:.4f})")
            
            # 4. ë°ì´í„° ê²€ì¦
            validation_passed, validation_message = self._validate_data_match(
                classification, context
            )
            print(f"âœ… ê²€ì¦: {validation_message}")
        
        # 5. ì‘ë‹µ ìƒì„±
        response, needs_dashboard = self._generate_response(
            query=query,
            query_type=classification.query_type,
            context=context,
            validation_message=validation_message
        )
        
        print(f"ğŸ“Š ëŒ€ì‹œë³´ë“œ ì¶”ì²œ: {needs_dashboard}")
        
        return ChainResult(
            query=query,
            query_type=classification.query_type,
            teams=all_teams,
            context=context,
            retrieval_score=retrieval_score,
            retrieval_method=retrieval_method,
            response=response,
            needs_dashboard=needs_dashboard,
            validation_passed=validation_passed
        )


# =============================================================================
# ì‹±ê¸€í†¤ ë° í¸ì˜ í•¨ìˆ˜
# =============================================================================

_chain_instance: Optional[KBOAnalysisChain] = None


def get_chain() -> KBOAnalysisChain:
    """ì²´ì¸ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _chain_instance
    if _chain_instance is None:
        _chain_instance = KBOAnalysisChain()
    return _chain_instance


def run_analysis(query: str) -> ChainResult:
    """
    ë¶„ì„ ì²´ì¸ì„ ì‹¤í–‰í•˜ëŠ” í¸ì˜ í•¨ìˆ˜
    
    Args:
        query: ì‚¬ìš©ì ì¿¼ë¦¬
    
    Returns:
        ChainResult: ë¶„ì„ ê²°ê³¼
    
    Example:
        >>> from src.chain import run_analysis
        >>> result = run_analysis("í•œí™” ì˜¬ì‹œì¦Œ íƒ€ì„  ë¶„ì„í•´ì¤˜")
        >>> print(result.response)
    """
    chain = get_chain()
    return chain.run(query)


# =============================================================================
# CLI í…ŒìŠ¤íŠ¸
# =============================================================================

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
    test_queries = [
        "WARê°€ ë­ì•¼?",
        "í•œí™” ì˜¬ì‹œì¦Œ ì„±ì  ì–´ë•Œ?",
        "ì–´ì œ LG ê²½ê¸° ê²°ê³¼ ì•Œë ¤ì¤˜",
    ]
    
    chain = KBOAnalysisChain()
    
    for query in test_queries:
        result = chain.run(query)
        
        print(f"\n{'='*60}")
        print(f"ğŸ“ ì‘ë‹µ:")
        print(f"{'='*60}")
        print(result.response[:500] + "..." if len(result.response) > 500 else result.response)
        print(f"\nğŸ¯ ëŒ€ì‹œë³´ë“œ í•„ìš”: {result.needs_dashboard}")
