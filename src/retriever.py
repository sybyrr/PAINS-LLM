"""
Retriever module - í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œìŠ¤í…œ

ë©”íƒ€ë°ì´í„° í•„í„°ë§ê³¼ ì‹œë§¨í‹± ê²€ìƒ‰ì„ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì„ ì œê³µí•©ë‹ˆë‹¤.
ë…¼ë¬¸ Section 4.4 (RAG) ë° 4.4.2 (Hybrid Retrieval Strategy)ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

í•µì‹¬ ì „ëµ:
1. ì‹œë§¨í‹± ê²€ìƒ‰ ìš°ì„  (ì„ë² ë”© ê¸°ë°˜ ìœ ì‚¬ë„)
2. ì‹ ë¢°ë„ ì„ê³„ê°’ ë¯¸ë‹¬ì‹œ BM25 í´ë°±
3. ë©”íƒ€ë°ì´í„° í•„í„°ë§ìœ¼ë¡œ ê²€ìƒ‰ ë²”ìœ„ ì¶•ì†Œ
"""

import json
from typing import List, Dict, Optional, Tuple
from langchain_chroma import Chroma
from langchain.schema import Document
from langchain_community.retrievers import BM25Retriever
from langchain.retrievers import EnsembleRetriever

from openai import OpenAI

from .config import (
    CHROMA_DB_DIR,
    COLLECTION_NAME,
    RETRIEVAL_TOP_K,
    SIMILARITY_THRESHOLD
)
from .ingest import get_embedding_model, initialize_vector_store
from .utils import (
    build_metadata_filter,
    clean_query_for_embedding,
    extract_teams_from_query
)


# =============================================================================
# ì¿¼ë¦¬ ë²ˆì—­ (í•œêµ­ì–´ â†’ ì˜ì–´)
# =============================================================================

_openai_client: OpenAI = None


def get_openai_client() -> OpenAI:
    """OpenAI í´ë¼ì´ì–¸íŠ¸ ì‹±ê¸€í†¤"""
    global _openai_client
    if _openai_client is None:
        _openai_client = OpenAI()
    return _openai_client


def translate_query_to_english(query: str) -> str:
    """
    í•œêµ­ì–´ ì¿¼ë¦¬ë¥¼ ì™„ì „íˆ ì˜ì–´ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤.
    
    ì„ ìˆ˜ ì´ë¦„, íŒ€ ì´ë¦„, ì•¼êµ¬ ìš©ì–´ ëª¨ë‘ ì˜ì–´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    Descriptionë„ ì˜ì–´ë¡œ ì €ì¥ë˜ì–´ ìˆì–´ ì˜ì–´-ì˜ì–´ ë¹„êµë¡œ ìœ ì‚¬ë„ê°€ ë†’ì•„ì§‘ë‹ˆë‹¤.
    
    Args:
        query: í•œêµ­ì–´ ì¿¼ë¦¬
    
    Returns:
        str: ì™„ì „íˆ ì˜ì–´ë¡œ ë²ˆì—­ëœ ì¿¼ë¦¬
    """
    client = get_openai_client()
    
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {
                "role": "system",
                "content": (
                    "You are a translator for KBO (Korean Baseball Organization) queries. "
                    "Translate the Korean query completely to English:\n"
                    "1. Romanize player names (e.g., ë¥˜í˜„ì§„ â†’ Ryu Hyun-jin, í›„ë¼ë„ â†’ Hueraldo)\n"
                    "2. Translate team names (e.g., í•œí™” â†’ Hanwha, ë¡¯ë° â†’ Lotte)\n"
                    "3. Translate baseball terms (e.g., ì‹œì¦Œ ì„±ì  â†’ season stats, ë°©ì–´ìœ¨ â†’ ERA)\n"
                    "4. Remove adjectives/filler words (e.g., 'ì§„ì§œ ì˜í•˜ëŠ”' â†’ remove)\n"
                    "5. Output ONLY the translated query, nothing else.\n\n"
                    "Examples:\n"
                    "- 'ë¥˜í˜„ì§„ 2025 ì‹œì¦Œ ì„±ì ' â†’ 'Ryu Hyun-jin 2025 season stats'\n"
                    "- 'ì§„ì§œ ì˜í•˜ëŠ” í›„ë¼ë„ 2025ì‹œì¦Œ ì„±ì ' â†’ 'Hueraldo 2025 season stats'\n"
                    "- 'í•œí™” ì´ê¸€ìŠ¤ ì˜¬ì‹œì¦Œ íˆ¬ìˆ˜ ë¶„ì„' â†’ 'Hanwha Eagles this season pitching analysis'"
                )
            },
            {"role": "user", "content": query}
        ],
        temperature=0
    )
    
    return response.choices[0].message.content.strip()


# =============================================================================
# ë²¡í„° ìŠ¤í† ì–´ ì ‘ê·¼
# =============================================================================
_vector_store: Optional[Chroma] = None


def get_vector_store() -> Chroma:
    """
    ë²¡í„° ìŠ¤í† ì–´ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Returns:
        Chroma: ë²¡í„° ìŠ¤í† ì–´ ì¸ìŠ¤í„´ìŠ¤
    """
    global _vector_store
    if _vector_store is None:
        _vector_store = initialize_vector_store(
            documents=None,  # ê¸°ì¡´ ìŠ¤í† ì–´ ë¡œë“œ
            persist_directory=str(CHROMA_DB_DIR),
            collection_name=COLLECTION_NAME
        )
    return _vector_store


# =============================================================================
# ì‹œë§¨í‹± ê²€ìƒ‰
# =============================================================================

def semantic_search(
    query: str,
    top_k: int = RETRIEVAL_TOP_K,
    metadata_filter: Dict = None,
    verbose: bool = False
) -> List[Tuple[Document, float]]:
    """
    ì‹œë§¨í‹± ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    ì„ë² ë”© ìœ ì‚¬ë„ ê¸°ë°˜ìœ¼ë¡œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    í•œêµ­ì–´ ì¿¼ë¦¬ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•˜ì—¬ ì˜ì–´ descriptionê³¼ ë¹„êµí•©ë‹ˆë‹¤.
    
    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        top_k: ë°˜í™˜í•  ìµœëŒ€ ë¬¸ì„œ ìˆ˜
        metadata_filter: ChromaDB where í•„í„°
        verbose: ë²ˆì—­ ê²°ê³¼ ì¶œë ¥ ì—¬ë¶€
    
    Returns:
        List[Tuple[Document, float]]: (ë¬¸ì„œ, ìœ ì‚¬ë„ ì ìˆ˜) ëª©ë¡
    """
    vector_store = get_vector_store()
    
    # í•œêµ­ì–´ ì¿¼ë¦¬ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­ (ì˜ì–´ descriptionê³¼ ë¹„êµí•˜ê¸° ìœ„í•´)
    translated_query = translate_query_to_english(query)
    
    if verbose:
        print(f"ğŸ“ ì›ë³¸ ì¿¼ë¦¬: {query}")
        print(f"ğŸ”„ ë²ˆì—­ ì¿¼ë¦¬: {translated_query}")
    
    # Instruct ëª¨ë¸ìš© ì¿¼ë¦¬ í¬ë§·íŒ…
    # ë…¼ë¬¸ Section 4.4.1ì—ì„œ ê²€ì¦ëœ í˜•ì‹
    formatted_query = (
        f"Instruct: Find the baseball dataset covering the given team(s) and statistics. "
        f"Query: {translated_query}"
    )
    
    # ë©”íƒ€ë°ì´í„° í•„í„°ê°€ ìˆëŠ” ê²½ìš°
    if metadata_filter:
        results = vector_store.similarity_search_with_relevance_scores(
            query=formatted_query,
            k=top_k,
            filter=metadata_filter
        )
    else:
        results = vector_store.similarity_search_with_relevance_scores(
            query=formatted_query,
            k=top_k
        )
    
    return results


def get_all_documents_for_bm25() -> List[Document]:
    """
    BM25 ê²€ìƒ‰ì„ ìœ„í•´ ëª¨ë“  ë¬¸ì„œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    
    Returns:
        List[Document]: ëª¨ë“  ë¬¸ì„œ ëª©ë¡
    """
    vector_store = get_vector_store()
    
    # ChromaDBì—ì„œ ëª¨ë“  ë¬¸ì„œ ì¡°íšŒ
    collection = vector_store._collection
    results = collection.get(include=["documents", "metadatas"])
    
    documents = []
    for doc_text, metadata in zip(results["documents"], results["metadatas"]):
        documents.append(Document(
            page_content=doc_text,
            metadata=metadata or {}
        ))
    
    return documents


# =============================================================================
# í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
# =============================================================================

def hybrid_search(
    query: str,
    teams: List[str] = None,
    data_type: str = None,
    date: str = None,
    top_k: int = RETRIEVAL_TOP_K,
    similarity_threshold: float = SIMILARITY_THRESHOLD
) -> Tuple[Optional[Document], float, str]:
    """
    í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    ë…¼ë¬¸ Section 4.4.2 ì „ëµ:
    1. ì‹œë§¨í‹± ê²€ìƒ‰ìœ¼ë¡œ ìƒìœ„ Kê°œ í›„ë³´ ê²€ìƒ‰
    2. ìµœê³  ì ìˆ˜ê°€ ì„ê³„ê°’ ì´ìƒì´ë©´ í•´ë‹¹ ê²°ê³¼ ë°˜í™˜
    3. ì„ê³„ê°’ ë¯¸ë‹¬ì‹œ BM25 ì•™ìƒë¸” í´ë°±
    
    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        teams: í•„í„°ë§í•  íŒ€ ëª©ë¡ (ì •ê·œí™”ëœ ì˜ë¬¸ëª…)
        data_type: ë°ì´í„° ìœ í˜• ("season" ë˜ëŠ” "match")
        date: ê²½ê¸° ë‚ ì§œ (match_analysisì¸ ê²½ìš°)
        top_k: ê²€ìƒ‰í•  ìµœëŒ€ ë¬¸ì„œ ìˆ˜
        similarity_threshold: ì‹œë§¨í‹± ê²€ìƒ‰ ì‹ ë¢°ë„ ì„ê³„ê°’
    
    Returns:
        Tuple[Optional[Document], float, str]: 
            (ê²€ìƒ‰ëœ ë¬¸ì„œ, ì‹ ë¢°ë„ ì ìˆ˜, ê²€ìƒ‰ ë°©ë²•)
    
    Example:
        >>> doc, score, method = hybrid_search(
        ...     query="í•œí™” ì‹œì¦Œ ì„±ì ",
        ...     teams=["Hanwha"],
        ...     data_type="season"
        ... )
        >>> print(f"ê²€ìƒ‰ ë°©ë²•: {method}, ì ìˆ˜: {score:.2f}")
    """
    # 1. ë©”íƒ€ë°ì´í„° í•„í„° êµ¬ì„±
    metadata_filter = build_metadata_filter(
        teams=teams,
        data_type=data_type,
        date=date
    )
    
    # 2. ê²€ìƒ‰ ì¿¼ë¦¬ ì •ì œ (ë…¼ë¬¸ Section 4.3.2: Fully Cleaned ì¿¼ë¦¬)
    # data_typeì„ query_typeìœ¼ë¡œ ë³€í™˜
    query_type_map = {"season": "season_analysis", "game": "match_analysis"}
    query_type = query_type_map.get(data_type)
    
    cleaned_query = clean_query_for_embedding(query, teams, date, query_type)
    
    print(f"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: {cleaned_query}")
    if metadata_filter:
        print(f"ğŸ“‹ ë©”íƒ€ë°ì´í„° í•„í„°: {metadata_filter}")
    
    # 3. ì‹œë§¨í‹± ê²€ìƒ‰ ìˆ˜í–‰
    semantic_results = semantic_search(
        query=cleaned_query,
        top_k=top_k,
        metadata_filter=metadata_filter
    )
    
    # ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°
    if not semantic_results:
        print("âš ï¸ ì‹œë§¨í‹± ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ, í•„í„° ì—†ì´ ì¬ê²€ìƒ‰...")
        # í•„í„° ì—†ì´ ì¬ì‹œë„
        semantic_results = semantic_search(
            query=cleaned_query,
            top_k=top_k,
            metadata_filter=None
        )
        
        if not semantic_results:
            return None, 0.0, "no_results"
    
    # 3.5. íŒ€ í•„í„°ë§ í›„ì²˜ë¦¬ (ChromaDB í•„í„°ì™€ ì¤‘ë³µ í™•ì¸ìš©)
    if teams:
        filtered_results = []
        for doc, score in semantic_results:
            home_team = doc.metadata.get("home_team", "")
            away_team = doc.metadata.get("away_team", "")
            doc_teams = {home_team, away_team}
            
            # ìš”ì²­ëœ ëª¨ë“  íŒ€ì´ home_team ë˜ëŠ” away_teamì— ìˆëŠ”ì§€ í™•ì¸
            if all(team in doc_teams for team in teams):
                filtered_results.append((doc, score))
        
        if filtered_results:
            semantic_results = filtered_results
            print(f"ğŸ“‹ íŒ€ í•„í„° í›„ì²˜ë¦¬ ì ìš©: {len(filtered_results)}ê°œ ê²°ê³¼")
        else:
            print(f"âš ï¸ íŒ€ í•„í„° í›„ ë§¤ì¹­ ê²°ê³¼ ì—†ìŒ, ì›ë³¸ ê²°ê³¼ ìœ ì§€")
    
    # 4. ìµœê³  ì ìˆ˜ í™•ì¸
    top_doc, top_score = semantic_results[0]
    
    print(f"ğŸ“Š ì‹œë§¨í‹± ê²€ìƒ‰ ìµœê³  ì ìˆ˜: {top_score:.4f}")
    
    # 5. ì„ê³„ê°’ ì²´í¬
    if top_score >= similarity_threshold:
        # ì‹œë§¨í‹± ê²€ìƒ‰ ê²°ê³¼ ì‚¬ìš©
        return top_doc, top_score, "semantic"
    
    # 6. í´ë°±: ì•™ìƒë¸” ê²€ìƒ‰ (ì‹œë§¨í‹± + BM25)
    print(f"âš ï¸ ì ìˆ˜ {top_score:.4f} < ì„ê³„ê°’ {similarity_threshold}, ì•™ìƒë¸” í´ë°± ìˆ˜í–‰")
    
    try:
        # BM25 ê²€ìƒ‰ê¸° êµ¬ì„±
        all_docs = get_all_documents_for_bm25()
        
        if len(all_docs) < 2:
            # ë¬¸ì„œê°€ ì ìœ¼ë©´ ì‹œë§¨í‹± ê²°ê³¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            return top_doc, top_score, "semantic_fallback"
        
        bm25_retriever = BM25Retriever.from_documents(all_docs)
        bm25_retriever.k = top_k
        
        # ì‹œë§¨í‹± ê²€ìƒ‰ê¸° ë˜í•‘
        vector_store = get_vector_store()
        semantic_retriever = vector_store.as_retriever(
            search_kwargs={
                "k": top_k,
                "filter": metadata_filter if metadata_filter else None
            }
        )
        
        # ì•™ìƒë¸” ê²€ìƒ‰ê¸° (ë…¼ë¬¸: ì‹œë§¨í‹± 0.8, BM25 0.2)
        ensemble_retriever = EnsembleRetriever(
            retrievers=[semantic_retriever, bm25_retriever],
            weights=[0.8, 0.2]
        )
        
        ensemble_results = ensemble_retriever.invoke(cleaned_query)
        
        if ensemble_results:
            return ensemble_results[0], top_score, "ensemble"
        else:
            return top_doc, top_score, "semantic_fallback"
            
    except Exception as e:
        print(f"âš ï¸ ì•™ìƒë¸” ê²€ìƒ‰ ì‹¤íŒ¨: {e}, ì‹œë§¨í‹± ê²°ê³¼ ì‚¬ìš©")
        return top_doc, top_score, "semantic_fallback"


# =============================================================================
# ê²€ìƒ‰ ê²°ê³¼ í›„ì²˜ë¦¬ (Post-Retrieval Data Preparation)
# ë…¼ë¬¸ Section 4.4.3: í† í° ì ˆì•½ì„ ìœ„í•œ ë°ì´í„° ì •ì œ
# =============================================================================

def extract_raw_data(document: Document) -> Dict:
    """
    Documentì—ì„œ ì›ë³¸ JSON ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Args:
        document: LangChain Document
    
    Returns:
        Dict: ì›ë³¸ JSON ë°ì´í„°
    """
    # ë©”íƒ€ë°ì´í„°ì—ì„œ ì›ë³¸ ë°ì´í„° ì¶”ì¶œ (original_data ë˜ëŠ” raw_data)
    raw_data_str = document.metadata.get("original_data") or document.metadata.get("raw_data", "{}")
    
    try:
        return json.loads(raw_data_str)
    except json.JSONDecodeError:
        return {}


def prepare_context_for_llm(
    document: Document,
    query_teams: List[str] = None
) -> Dict:
    """
    LLM ì»¨í…ìŠ¤íŠ¸ìš© ë°ì´í„°ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.
    
    ë…¼ë¬¸ Section 4.4.3 (Post-Retrieval Data Preparation):
    - clean_opponent: ìš”ì²­ëœ íŒ€ ë°ì´í„°ë§Œ í•„í„°ë§ (QRatio >= 60)
    - clean_game: í—¤ë” ì •ë³´ ì œê±°
    - 'headers' ì†ì„± ì œê±°ë¡œ ì•½ 600 í† í° ì ˆì•½
    
    Args:
        document: ê²€ìƒ‰ëœ Document
        query_teams: ì¿¼ë¦¬ì—ì„œ ì¶”ì¶œëœ íŒ€ ëª©ë¡ (í•„í„°ë§ìš©)
    
    Returns:
        Dict: ì •ì œëœ ì»¨í…ìŠ¤íŠ¸ ë°ì´í„°
    """
    raw_data = extract_raw_data(document)
    data_type = document.metadata.get("type")
    
    # =================================================================
    # ë…¼ë¬¸ 4.4.3: 'headers' ì†ì„± ì œê±° (ì•½ 600 í† í° ì ˆì•½)
    # =================================================================
    raw_data.pop("headers", None)
    
    # =================================================================
    # ë…¼ë¬¸ 4.4.3: clean_opponent - íŒ€ í•„í„°ë§ (ì‹œì¦Œ ë°ì´í„°)
    # QRatio < 60ì¸ ì„ ìˆ˜ ë°ì´í„° ì œê±°, >= 60ì¸ ê²½ìš° LLMì´ ìµœì¢… íŒë‹¨
    # =================================================================
    if data_type == "season" and query_teams:
        from rapidfuzz import fuzz
        
        if "players" in raw_data and isinstance(raw_data["players"], list):
            filtered_players = []
            for player in raw_data["players"]:
                player_team = player.get("team", "")
                for query_team in query_teams:
                    # QRatio >= 60: ìœ ì§€ (LLMì´ ìµœì¢… íŒë‹¨)
                    # QRatio < 60: ì œê±° (í™•ì‹¤íˆ ë‹¤ë¥¸ íŒ€)
                    if fuzz.QRatio(player_team.lower(), query_team.lower()) >= 60:
                        filtered_players.append(player)
                        break
            raw_data["players"] = filtered_players
        
        raw_data["_filtered_for_teams"] = query_teams
    
    # =================================================================
    # ë…¼ë¬¸ 4.4.3: clean_game - ì¤‘ë³µ í—¤ë” ì •ë³´ ì œê±° (ê²½ê¸° ë°ì´í„°)
    # =================================================================
    # í—¤ë”ëŠ” ì´ë¯¸ ìœ„ì—ì„œ ì œê±°ë¨
    
    # teams ë©”íƒ€ë°ì´í„° íŒŒì‹± (game ë°ì´í„°ëŠ” home_team, away_teamìœ¼ë¡œ ì €ì¥ë¨)
    home_team = document.metadata.get("home_team", "")
    away_team = document.metadata.get("away_team", "")
    
    if home_team and away_team:
        # game ë°ì´í„°: home_team, away_teamì—ì„œ íŒ€ ëª©ë¡ êµ¬ì„±
        teams_list = [home_team, away_team]
    else:
        # season ë°ì´í„°: team í•„ë“œ ì‚¬ìš©
        team = document.metadata.get("team", "")
        teams_list = [team] if team else []
    
    return {
        "type": document.metadata.get("type"),
        "teams": teams_list,
        "home_team": home_team,
        "away_team": away_team,
        "date": document.metadata.get("date"),
        "season": document.metadata.get("season"),
        "data": raw_data
    }


# =============================================================================
# í†µí•© ê²€ìƒ‰ ì¸í„°í˜ì´ìŠ¤
# =============================================================================

def retrieve_for_query(
    query: str,
    query_type: str,
    teams: List[str] = None,
    date: str = None
) -> Tuple[Optional[Dict], float, str]:
    """
    ì¿¼ë¦¬ ìœ í˜•ì— ë§ëŠ” ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    chain.pyì—ì„œ í˜¸ì¶œí•˜ëŠ” í†µí•© ê²€ìƒ‰ ì¸í„°í˜ì´ìŠ¤ì…ë‹ˆë‹¤.
    
    Args:
        query: ì‚¬ìš©ì ì¿¼ë¦¬
        query_type: ì¿¼ë¦¬ ìœ í˜• ("season_analysis" ë˜ëŠ” "match_analysis")
        teams: ì •ê·œí™”ëœ íŒ€ ëª©ë¡
        date: ê²½ê¸° ë‚ ì§œ (match_analysisì¸ ê²½ìš°)
    
    Returns:
        Tuple[Optional[Dict], float, str]:
            (ì»¨í…ìŠ¤íŠ¸ ë°ì´í„°, ì‹ ë¢°ë„ ì ìˆ˜, ê²€ìƒ‰ ë°©ë²•)
    """
    # ë°ì´í„° íƒ€ì… ê²°ì • (DBì— ì €ì¥ëœ íƒ€ì…ëª…ê³¼ ì¼ì¹˜ì‹œí‚´)
    if query_type == "match_analysis":
        data_type = "game"  # DBì—ëŠ” "game"ìœ¼ë¡œ ì €ì¥ë¨
    elif query_type == "season_analysis":
        data_type = "season"
    else:
        data_type = None  # í•„í„° ì—†ìŒ
    
    # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìˆ˜í–‰
    document, score, method = hybrid_search(
        query=query,
        teams=teams,
        data_type=data_type,
        date=date
    )
    
    if document is None:
        return None, 0.0, method
    
    # ì»¨í…ìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
    context = prepare_context_for_llm(document, teams)
    
    return context, score, method


# =============================================================================
# í¸ì˜ í•¨ìˆ˜ (ê¸°ì¡´ ìŠ¤ì¼ˆë ˆí†¤ í˜¸í™˜)
# =============================================================================

def keyword_search(query: str, top_k: int = 5):
    """
    í‚¤ì›Œë“œ ê¸°ë°˜ BM25 ê²€ìƒ‰ (ë ˆê±°ì‹œ í˜¸í™˜ìš©)
    """
    all_docs = get_all_documents_for_bm25()
    
    if not all_docs:
        return []
    
    bm25_retriever = BM25Retriever.from_documents(all_docs)
    bm25_retriever.k = top_k
    
    return bm25_retriever.invoke(query)


# =============================================================================
# CLI í…ŒìŠ¤íŠ¸
# =============================================================================

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
    test_cases = [
        {
            "query": "í•œí™” ì‹œì¦Œ ì„±ì ",
            "query_type": "season_analysis",
            "teams": ["Hanwha"]
        },
        {
            "query": "LG ë‘ì‚° ê²½ê¸°",
            "query_type": "match_analysis",
            "teams": ["LG", "Doosan"]
        },
    ]
    
    for case in test_cases:
        print(f"\n{'='*60}")
        print(f"ì¿¼ë¦¬: {case['query']}")
        print(f"{'='*60}")
        
        context, score, method = retrieve_for_query(
            query=case["query"],
            query_type=case["query_type"],
            teams=case.get("teams")
        )
        
        if context:
            print(f"âœ… ê²€ìƒ‰ ì„±ê³µ ({method})")
            print(f"   ì ìˆ˜: {score:.4f}")
            print(f"   íƒ€ì…: {context['type']}")
            print(f"   íŒ€: {context['teams']}")
        else:
            print(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {method}")
