{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e559a3d",
   "metadata": {},
   "source": [
    "# KBO ì•¼êµ¬ íŠ¹í™” ì±—ë´‡ \n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ ë…¼ë¬¸ \"A Chatbot for Football Analytics\" ì•„í‚¤í…ì²˜ë¥¼ KBO ì•¼êµ¬ì— ì ìš©í•œ ì±—ë´‡ì˜ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "## ì£¼ìš” êµ¬ì„± ìš”ì†Œ\n",
    "1. **ë°ì´í„° ì ìž¬ (Ingest)**: JSON â†’ ChromaDB ë²¡í„° ì €ìž¥ì†Œ\n",
    "2. **ì¿¼ë¦¬ ë¶„ë¥˜ (Classifier)**: general / season_analysis / match_analysis\n",
    "3. **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (Retriever)**: Semantic + BM25\n",
    "4. **ì‘ë‹µ ìƒì„± (Chain)**: LLM ê¸°ë°˜ ë¶„ì„\n",
    "5. **ì—ì´ì „íŠ¸ (Agent)**: Function Calling ì§€ì›\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9451a4e",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ\n",
    "\n",
    "í™˜ê²½ ë³€ìˆ˜ë¥¼ `.env` íŒŒì¼ì—ì„œ ë¡œë“œí•˜ê³ , API í‚¤ê°€ ì•ˆì „í•˜ê²Œ ê´€ë¦¬ë˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cbed6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# API í‚¤ í™•ì¸ (ê°’ì€ ì¶œë ¥í•˜ì§€ ì•ŠìŒ - ë³´ì•ˆ)\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(f\"âœ… í”„ë¡œì íŠ¸ ë£¨íŠ¸: {PROJECT_ROOT}\")\n",
    "print(f\"âœ… OPENAI_API_KEY ë¡œë“œ: {'ì„±ê³µ âœ“' if api_key else 'ì‹¤íŒ¨ âœ— (.env íŒŒì¼ í™•ì¸ í•„ìš”)'}\")\n",
    "\n",
    "if not api_key:\n",
    "    print(\"\\nâš ï¸ .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”:\")\n",
    "    print(\"   OPENAI_API_KEY=sk-your-api-key-here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8244469c",
   "metadata": {},
   "source": [
    "## 2. í”„ë¡œì íŠ¸ íŒŒì¼ êµ¬ì¡° ë¶„ì„\n",
    "\n",
    "í˜„ìž¬ í”„ë¡œì íŠ¸ì˜ íŒŒì¼ êµ¬ì¡°ë¥¼ íŠ¸ë¦¬ í˜•íƒœë¡œ ì¶œë ¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eef580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(path: Path, prefix: str = \"\", ignore: set = None):\n",
    "    \"\"\"ë””ë ‰í† ë¦¬ êµ¬ì¡°ë¥¼ íŠ¸ë¦¬ í˜•íƒœë¡œ ì¶œë ¥\"\"\"\n",
    "    if ignore is None:\n",
    "        ignore = {'.git', '__pycache__', '.venv', 'node_modules', '.vscode', 'chroma_db'}\n",
    "    \n",
    "    items = sorted(path.iterdir(), key=lambda x: (x.is_file(), x.name))\n",
    "    items = [i for i in items if i.name not in ignore]\n",
    "    \n",
    "    for i, item in enumerate(items):\n",
    "        is_last = i == len(items) - 1\n",
    "        current_prefix = \"â””â”€â”€ \" if is_last else \"â”œâ”€â”€ \"\n",
    "        print(f\"{prefix}{current_prefix}{item.name}\")\n",
    "        \n",
    "        if item.is_dir():\n",
    "            next_prefix = \"    \" if is_last else \"â”‚   \"\n",
    "            print_tree(item, prefix + next_prefix, ignore)\n",
    "\n",
    "print(\"ðŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°:\\n\")\n",
    "print_tree(PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154cef62",
   "metadata": {},
   "source": [
    "## 3. í•µì‹¬ ëª¨ë“ˆ ìž„í¬íŠ¸\n",
    "\n",
    "`src/` ë””ë ‰í† ë¦¬ì˜ í•µì‹¬ ëª¨ë“ˆë“¤ì„ ìž„í¬íŠ¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdd79d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•µì‹¬ ëª¨ë“ˆ ìž„í¬íŠ¸\n",
    "from src.config import (\n",
    "    CHROMA_DB_DIR, COLLECTION_NAME, EMBEDDING_MODEL,\n",
    "    SEASON_DATA_DIR, MATCH_DATA_DIR, LLM_MODEL, RETRIEVAL_TOP_K\n",
    ")\n",
    "\n",
    "print(\"ðŸ“¦ ì„¤ì • ì •ë³´:\")\n",
    "print(f\"   - ìž„ë² ë”© ëª¨ë¸: {EMBEDDING_MODEL}\")\n",
    "print(f\"   - LLM ëª¨ë¸: {LLM_MODEL}\")\n",
    "print(f\"   - ChromaDB ê²½ë¡œ: {CHROMA_DB_DIR}\")\n",
    "print(f\"   - ì»¬ë ‰ì…˜ ì´ë¦„: {COLLECTION_NAME}\")\n",
    "print(f\"   - ì‹œì¦Œ ë°ì´í„°: {SEASON_DATA_DIR}\")\n",
    "print(f\"   - ê²½ê¸° ë°ì´í„°: {MATCH_DATA_DIR}\")\n",
    "print(f\"   - Top-K ê²€ìƒ‰: {RETRIEVAL_TOP_K}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6332ebcc",
   "metadata": {},
   "source": [
    "## 4. ë°ì´í„° ì ìž¬ (Ingest)\n",
    "\n",
    "JSON ë°ì´í„°ë¥¼ ChromaDB ë²¡í„° ì €ìž¥ì†Œì— ì ìž¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "### í•µì‹¬ ì „ëžµ (ë…¼ë¬¸ Section 4.2)\n",
    "- JSONì„ ê·¸ëŒ€ë¡œ ìž„ë² ë”©í•˜ì§€ ì•ŠìŒ\n",
    "- **ì„œìˆ í˜• ë¬¸ìž¥(Descriptive Sentence)** ì„ ìƒì„±í•˜ì—¬ ìž„ë² ë”©\n",
    "- ì›ë³¸ ë°ì´í„°ëŠ” metadataì— ì €ìž¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8de0d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ingest import ingest_all_data, initialize_vector_store\n",
    "\n",
    "# ë°ì´í„° ì ìž¬ ì‹¤í–‰\n",
    "# clear_existing=True: ê¸°ì¡´ DB ì‚­ì œ í›„ ìž¬ì ìž¬\n",
    "result = ingest_all_data(clear_existing=True)\n",
    "\n",
    "if result:\n",
    "    doc_count = result._collection.count()\n",
    "    print(f\"\\nðŸŽ‰ ë²¡í„° ìŠ¤í† ì–´ ì¤€ë¹„ ì™„ë£Œ! ë¬¸ì„œ ìˆ˜: {doc_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf55e26",
   "metadata": {},
   "source": [
    "## 5. ì¿¼ë¦¬ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸ (Classifier)\n",
    "\n",
    "ì‚¬ìš©ìž ì¿¼ë¦¬ë¥¼ `general`, `season_analysis`, `match_analysis` ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb88c201",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.classifier import classify_query\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤\n",
    "test_queries = [\n",
    "    \"ì•¼êµ¬ ê·œì¹™ ì„¤ëª…í•´ì¤˜\",              # general\n",
    "    \"í•œí™” ì´ê¸€ìŠ¤ ì˜¬ì‹œì¦Œ ì„±ì  ë¶„ì„í•´ì¤˜\",   # season_analysis\n",
    "    \"ì–´ì œ í•œí™” LG ê²½ê¸° ì–´ë• ì–´?\",        # match_analysis\n",
    "]\n",
    "\n",
    "print(\"ðŸ” ì¿¼ë¦¬ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸:\\n\")\n",
    "for query in test_queries:\n",
    "    result = classify_query(query)\n",
    "    print(f\"ì¿¼ë¦¬: {query}\")\n",
    "    print(f\"  â†’ ë¶„ë¥˜: {result.query_type}\")\n",
    "    print(f\"  â†’ íŒ€: {result.teams}\")\n",
    "    print(f\"  â†’ ì‹ ë¢°ë„: {result.confidence:.0%}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810267cc",
   "metadata": {},
   "source": [
    "## 6. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ (Retriever)\n",
    "\n",
    "Semantic Search + BM25ë¥¼ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54df9189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.retriever import retrieve_for_query\n",
    "\n",
    "# ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "test_query = \"í•œí™” ì´ê¸€ìŠ¤ ì‹œì¦Œ ì„±ì \"\n",
    "\n",
    "print(f\"ðŸ”Ž ê²€ìƒ‰ ì¿¼ë¦¬: '{test_query}'\\n\")\n",
    "results = retrieve_for_query(test_query, top_k=3)\n",
    "\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"ê²°ê³¼ {i}:\")\n",
    "    print(f\"  íƒ€ìž…: {doc.metadata.get('type')}\")\n",
    "    print(f\"  íŒ€: {doc.metadata.get('teams', doc.metadata.get('team'))}\")\n",
    "    print(f\"  ë‚´ìš©: {doc.page_content[:100]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0263fb",
   "metadata": {},
   "source": [
    "## 7. ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (Chain)\n",
    "\n",
    "ë¶„ë¥˜ â†’ ê²€ìƒ‰ â†’ ìƒì„±ì˜ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f455cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.chain import run_analysis\n",
    "\n",
    "# ë¶„ì„ ì‹¤í–‰\n",
    "query = \"í•œí™” ì´ê¸€ìŠ¤ ì˜¬ì‹œì¦Œ ì„±ì  ë¶„ì„í•´ì¤˜\"\n",
    "print(f\"ðŸ’¬ ì§ˆë¬¸: {query}\\n\")\n",
    "\n",
    "result = run_analysis(query)\n",
    "\n",
    "print(f\"ðŸ“Š ë¶„ë¥˜: {result.query_type}\")\n",
    "print(f\"ðŸ“Š íŒ€: {result.teams}\")\n",
    "print(f\"ðŸ“Š ê²€ìƒ‰ ì ìˆ˜: {result.retrieval_score:.2%}\")\n",
    "print(f\"ðŸ“Š ëŒ€ì‹œë³´ë“œ í•„ìš”: {result.needs_dashboard}\")\n",
    "print(f\"\\nðŸ¤– ì‘ë‹µ:\\n{result.response[:500]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f288824f",
   "metadata": {},
   "source": [
    "## 8. ëŒ€í™”í˜• ì—ì´ì „íŠ¸ (Agent)\n",
    "\n",
    "Function Callingì„ ì§€ì›í•˜ëŠ” ëŒ€í™”í˜• ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7430c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agent import chat\n",
    "\n",
    "# ì—ì´ì „íŠ¸ ëŒ€í™” í…ŒìŠ¤íŠ¸\n",
    "queries = [\n",
    "    \"ì•ˆë…•! KBOì— ëŒ€í•´ ì•Œë ¤ì¤˜\",\n",
    "    \"í•œí™” ì´ê¸€ìŠ¤ ì˜¬ì‹œì¦Œ ì„±ì  ë¶„ì„í•´ì¤˜\",\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    print(f\"ðŸ‘¤ User: {q}\")\n",
    "    response = chat(q)\n",
    "    print(f\"ðŸ¤– Assistant: {response.response[:300]}...\")\n",
    "    if response.dashboard:\n",
    "        print(f\"   ðŸ“Š ëŒ€ì‹œë³´ë“œ ìƒì„±ë¨!\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb35289",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“ ë…¼ë¬¸ ëŒ€ë¹„ êµ¬í˜„ ì°¨ì´ì  ë° ChromaDB êµ¬ì„±\n",
    "\n",
    "### ë…¼ë¬¸ê³¼ ë™ì¼í•˜ê²Œ êµ¬í˜„í•œ ë¶€ë¶„\n",
    "| ë…¼ë¬¸ ì„¹ì…˜ | êµ¬í˜„ ë‚´ìš© |\n",
    "|----------|----------|\n",
    "| Section 4.2 (Embedding) | `multilingual-e5-large-instruct` ëª¨ë¸ ì‚¬ìš©, L2 ì •ê·œí™” |\n",
    "| Section 4.3.1 (Query Classification) | CoT í”„ë¡¬í”„íŒ…ìœ¼ë¡œ general/season/match ë¶„ë¥˜ |\n",
    "| Section 4.3.2 (Query Normalization) | RapidFuzz QRatio ìŠ¤ì½”ëŸ¬ë¡œ íŒ€ëª… í¼ì§€ ë§¤ì¹­ |\n",
    "| Section 4.4.1 (Instruct Format) | `\"Instruct: ... Query: ...\"` í¬ë§· ì‚¬ìš© |\n",
    "| Section 4.4.2 (Hybrid Retrieval) | Semantic (0.8) + BM25 (0.2) ì•™ìƒë¸” |\n",
    "| Section 4.5.4 (Function Calling) | ëŒ€ì‹œë³´ë“œ ìƒì„±ìš© ë„êµ¬ ì •ì˜ |\n",
    "\n",
    "### ë…¼ë¬¸ê³¼ ë‹¤ë¥´ê²Œ (KBOì— ë§žê²Œ) ìˆ˜ì •í•œ ë¶€ë¶„\n",
    "\n",
    "| í•­ëª© | ë…¼ë¬¸ (ì¶•êµ¬) | ì´ í”„ë¡œì íŠ¸ (ì•¼êµ¬) |\n",
    "|-----|-----------|------------------|\n",
    "| **ë„ë©”ì¸** | ìœ ëŸ½ ì¶•êµ¬ ë¦¬ê·¸ | KBO í•œêµ­ í”„ë¡œì•¼êµ¬ |\n",
    "| **TEAM_MAP** | ì¶•êµ¬íŒ€ + ëŒ€íšŒ ë§¤í•‘ | 10ê°œ KBO íŒ€ + í•œê¸€ ë³„ì¹­ |\n",
    "| **ë°ì´í„° êµ¬ì¡°** | ë¦¬ê·¸/ê²½ê¸° JSON | ì‹œì¦Œ/ê²½ê¸° JSON (ì•¼êµ¬ ìŠ¤íƒ¯) |\n",
    "| **KPI** | xG, íŒ¨ìŠ¤ ë“± | íƒ€ìœ¨, ë°©ì–´ìœ¨, OPS ë“± |\n",
    "| **Instruct í”„ë¡¬í”„íŠ¸** | \"football dataset\" | \"baseball dataset\" |\n",
    "\n",
    "### ChromaDB ë²¡í„° ì €ìž¥ì†Œ êµ¬ì„±\n",
    "\n",
    "```\n",
    "data/\n",
    "â””â”€â”€ chroma_db/           â† ë…¼ë¬¸ê³¼ ë™ì¼í•˜ê²Œ ë¡œì»¬ ì˜êµ¬ ì €ìž¥ì†Œ ì‚¬ìš©\n",
    "    â”œâ”€â”€ chroma.sqlite3   â† ë©”íƒ€ë°ì´í„° ì €ìž¥\n",
    "    â””â”€â”€ [UUID í´ë”ë“¤]/   â† ë²¡í„° ìž„ë² ë”© ì €ìž¥\n",
    "```\n",
    "\n",
    "- **ì €ìž¥ ìœ„ì¹˜**: `data/chroma_db/` (config.pyì˜ `CHROMA_DB_DIR`)\n",
    "- **ì»¬ë ‰ì…˜ ì´ë¦„**: `kbo_data` (config.pyì˜ `COLLECTION_NAME`)\n",
    "- **ìž„ë² ë”© ì°¨ì›**: 1024 (multilingual-e5-large-instruct)\n",
    "- **ì¸ë±ìŠ¤ ë°©ì‹**: HNSW (ChromaDB ê¸°ë³¸ê°’)\n",
    "\n",
    "> ðŸ’¡ ë…¼ë¬¸ì—ì„œëŠ” PlaymakerAI APIì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™”ì§€ë§Œ, ì´ í”„ë¡œì íŠ¸ëŠ” ë¡œì»¬ JSON íŒŒì¼ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "> ì´ëŠ” API ì—†ì´ë„ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìžˆë„ë¡ í•œ ì„¤ê³„ ê²°ì •ìž…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f3bbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChromaDB ìƒíƒœ í™•ì¸\n",
    "from src.ingest import initialize_vector_store\n",
    "\n",
    "vector_store = initialize_vector_store(documents=None)  # ê¸°ì¡´ ìŠ¤í† ì–´ ë¡œë“œ\n",
    "collection = vector_store._collection\n",
    "\n",
    "print(\"ðŸ—„ï¸ ChromaDB ë²¡í„° ì €ìž¥ì†Œ ì •ë³´:\")\n",
    "print(f\"   - ì €ìž¥ ê²½ë¡œ: {CHROMA_DB_DIR}\")\n",
    "print(f\"   - ì»¬ë ‰ì…˜ ì´ë¦„: {collection.name}\")\n",
    "print(f\"   - ë¬¸ì„œ ìˆ˜: {collection.count()}\")\n",
    "print(f\"   - ìž„ë² ë”© ëª¨ë¸: {EMBEDDING_MODEL}\")\n",
    "print(f\"   - ìž„ë² ë”© ì°¨ì›: 1024 (multilingual-e5-large-instruct)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c7b561",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Configuration\n",
    "\n",
    "Load environment variables and initialize required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bc6166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up project paths\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "RAW_DATA_DIR = DATA_DIR / \"raw\"\n",
    "CHROMA_DB_DIR = DATA_DIR / \"chroma_db\"\n",
    "SRC_DIR = PROJECT_ROOT / \"src\"\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(SRC_DIR))\n",
    "\n",
    "# Verify paths\n",
    "print(f\"Project Root: {PROJECT_ROOT}\")\n",
    "print(f\"Data Directory: {DATA_DIR}\")\n",
    "print(f\"Source Directory: {SRC_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a9883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# LLM and Vector DB\n",
    "# import openai\n",
    "# import chromadb\n",
    "# from langchain.embeddings import OpenAIEmbeddings\n",
    "# from langchain.vectorstores import Chroma\n",
    "\n",
    "# Web scraping\n",
    "# from selenium import webdriver\n",
    "# from bs4 import BeautifulSoup\n",
    "# import requests\n",
    "\n",
    "# Text processing\n",
    "# from rapidfuzz import fuzz, process\n",
    "\n",
    "# Local modules\n",
    "# from scraper import scrape_player_stats, scrape_matches\n",
    "# from data_processor import load_raw_json, process_player_data, process_match_data\n",
    "# from vector_store import initialize_chroma_db, embed_and_store, query_vector_store\n",
    "# from classifier import classify_query\n",
    "# from retriever import semantic_search, keyword_search, hybrid_search\n",
    "# from generator import generate_response, call_function, format_response\n",
    "\n",
    "print(\"âœ“ All imports configured successfully\")\n",
    "print(f\"OpenAI API Key configured: {'OPENAI_API_KEY' in os.environ}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a2d2d0",
   "metadata": {},
   "source": [
    "## 2. Data Scraping and Collection\n",
    "\n",
    "Scrape KBO/Statiz websites for player statistics and match data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3193f18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Data scraping configuration\n",
    "# NOTE: Uncomment and implement actual scraping logic when ready\n",
    "\n",
    "SCRAPING_CONFIG = {\n",
    "    \"seasons\": [2024, 2025],\n",
    "    \"targets\": {\n",
    "        \"player_stats\": \"https://www.statiz.co.kr/\",\n",
    "        \"match_results\": \"https://www.statiz.co.kr/game/\"\n",
    "    },\n",
    "    \"selenium_headless\": True,\n",
    "    \"request_timeout\": 30,\n",
    "    \"retry_count\": 3\n",
    "}\n",
    "\n",
    "print(\"Scraping Configuration:\")\n",
    "print(json.dumps(SCRAPING_CONFIG, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe624c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement actual scraping\n",
    "# Example function call:\n",
    "# player_data = scrape_player_stats(season=2024)\n",
    "# match_data = scrape_matches(season=2024, start_date=\"2024-03-01\", end_date=\"2024-10-31\")\n",
    "# Save to data/raw/season_2024/\n",
    "\n",
    "print(\"[SCRAPING STEP] - Ready to implement scraping logic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f356598a",
   "metadata": {},
   "source": [
    "## 3. Data Processing and Normalization\n",
    "\n",
    "Clean and structure scraped data into JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16edf01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data processing\n",
    "PROCESSING_CONFIG = {\n",
    "    \"input_format\": \"json\",\n",
    "    \"output_format\": \"json\",\n",
    "    \"standardization\": {\n",
    "        \"player_stats\": [\"name\", \"team\", \"position\", \"avg\", \"hr\", \"rbi\", \"era\", \"wins\"],\n",
    "        \"match_data\": [\"date\", \"home_team\", \"away_team\", \"home_score\", \"away_score\", \"box_score\"]\n",
    "    },\n",
    "    \"validation_rules\": {\n",
    "        \"required_fields\": True,\n",
    "        \"data_types\": True,\n",
    "        \"range_checks\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Processing Configuration:\")\n",
    "print(json.dumps(PROCESSING_CONFIG, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b7d484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement data processing\n",
    "# Example:\n",
    "# for json_file in RAW_DATA_DIR.glob('season_2024/*.json'):\n",
    "#     raw_data = load_raw_json(str(json_file))\n",
    "#     if 'player' in json_file.name:\n",
    "#         processed = process_player_data(raw_data)\n",
    "#     else:\n",
    "#         processed = process_match_data(raw_data)\n",
    "#     # Save processed data\n",
    "\n",
    "print(\"[DATA PROCESSING STEP] - Ready to implement processing logic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3387720",
   "metadata": {},
   "source": [
    "## 4. Vector Store Creation with ChromaDB\n",
    "\n",
    "Embed processed data and store in ChromaDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1bb226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector store configuration\n",
    "VECTOR_STORE_CONFIG = {\n",
    "    \"embedding_model\": \"text-embedding-ada-002\",\n",
    "    \"chunk_size\": 500,\n",
    "    \"chunk_overlap\": 50,\n",
    "    \"persist_directory\": str(CHROMA_DB_DIR),\n",
    "    \"collection_names\": [\n",
    "        \"player_statistics\",\n",
    "        \"match_records\",\n",
    "        \"season_analysis\"\n",
    "    ],\n",
    "    \"similarity_metric\": \"cosine\"\n",
    "}\n",
    "\n",
    "print(\"Vector Store Configuration:\")\n",
    "print(json.dumps(VECTOR_STORE_CONFIG, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761c9341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Initialize ChromaDB and create embeddings\n",
    "# Example:\n",
    "# chroma_client = initialize_chroma_db(persist_dir=str(CHROMA_DB_DIR))\n",
    "# \n",
    "# # Load and embed player statistics\n",
    "# player_docs = load_documents(DATA_DIR / \"raw\" / \"season_2024\")\n",
    "# embed_and_store(\n",
    "#     documents=player_docs,\n",
    "#     collection_name=\"player_statistics\"\n",
    "# )\n",
    "\n",
    "print(\"[VECTOR STORE STEP] - Ready to create embeddings and store in ChromaDB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551bcfab",
   "metadata": {},
   "source": [
    "## 5. Query Classification System\n",
    "\n",
    "Classify user queries using LLM-based classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90be9e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query classification configuration\n",
    "CLASSIFIER_CONFIG = {\n",
    "    \"model\": \"gpt-3.5-turbo\",\n",
    "    \"intent_types\": [\n",
    "        \"player_statistics\",\n",
    "        \"match_results\",\n",
    "        \"season_analysis\",\n",
    "        \"team_performance\",\n",
    "        \"prediction\",\n",
    "        \"comparison\",\n",
    "        \"general_question\"\n",
    "    ],\n",
    "    \"temperature\": 0.3,\n",
    "    \"max_tokens\": 200\n",
    "}\n",
    "\n",
    "print(\"Classifier Configuration:\")\n",
    "print(json.dumps(CLASSIFIER_CONFIG, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04721025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example queries for classification testing\n",
    "test_queries = [\n",
    "    \"2024ë…„ ìµœê³  íƒ€ìœ¨ì„ ê¸°ë¡í•œ ì„ ìˆ˜ëŠ” ëˆ„êµ¬ìž…ë‹ˆê¹Œ?\",\n",
    "    \"ì–´ì œ ì‚¼ì„±ê³¼ LGì˜ ê²½ê¸° ê²°ê³¼ëŠ”?\",\n",
    "    \"ì˜¬ ì‹œì¦Œ ê°•ì •í˜¸ ì„ ìˆ˜ì˜ í™ˆëŸ° í†µê³„ë¥¼ ë³´ì—¬ì¤˜\",\n",
    "    \"2024 ì •ê·œì‹œì¦Œê³¼ 2025 ì‹œìž‘ ì „ íŒ€ì˜ ì „ë ¥ì„ ë¹„êµí•´ì¤˜\",\n",
    "    \"ë‹¤ìŒ ì£¼ ìš°ë¦¬ íŒ€ì˜ ìŠ¹ë¦¬ í™•ë¥ ì€?\"\n",
    "]\n",
    "\n",
    "print(\"Example Queries for Classification:\")\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"{i}. {query}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38474066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement query classification\n",
    "# Example:\n",
    "# for query in test_queries:\n",
    "#     classification = classify_query(query)\n",
    "#     print(f\"Query: {query}\")\n",
    "#     print(f\"Classification: {classification}\")\n",
    "\n",
    "print(\"[CLASSIFICATION STEP] - Ready to classify user queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a558279a",
   "metadata": {},
   "source": [
    "## 6. Hybrid Retrieval Implementation\n",
    "\n",
    "Combine semantic search and keyword-based retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8847d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval configuration\n",
    "RETRIEVER_CONFIG = {\n",
    "    \"semantic_search\": {\n",
    "        \"model\": \"text-embedding-ada-002\",\n",
    "        \"top_k\": 5,\n",
    "        \"similarity_threshold\": 0.5\n",
    "    },\n",
    "    \"keyword_search\": {\n",
    "        \"method\": \"rapidfuzz\",\n",
    "        \"matcher\": \"token_sort_ratio\",\n",
    "        \"score_threshold\": 70,\n",
    "        \"top_k\": 5\n",
    "    },\n",
    "    \"hybrid_search\": {\n",
    "        \"semantic_weight\": 0.6,\n",
    "        \"keyword_weight\": 0.4,\n",
    "        \"top_k\": 10,\n",
    "        \"rerank\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Retriever Configuration:\")\n",
    "print(json.dumps(RETRIEVER_CONFIG, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef910b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement hybrid retrieval\n",
    "# Example:\n",
    "# query = \"2024ë…„ ì‚¼ì„± ë¼ì´ì˜¨ì¦ˆ ì„ ìˆ˜ í†µê³„\"\n",
    "# results = hybrid_search(\n",
    "#     query=query,\n",
    "#     top_k=10,\n",
    "#     alpha=0.6\n",
    "# )\n",
    "# \n",
    "# for doc in results:\n",
    "#     print(f\"Score: {doc['score']:.3f}\")\n",
    "#     print(f\"Content: {doc['content'][:200]}...\")\n",
    "\n",
    "print(\"[RETRIEVAL STEP] - Ready to perform hybrid search\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1f2f39",
   "metadata": {},
   "source": [
    "## 7. LLM Response Generation with Function Calling\n",
    "\n",
    "Generate responses using LLM with function calling capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17013040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Response generation configuration\n",
    "GENERATOR_CONFIG = {\n",
    "    \"model\": \"gpt-3.5-turbo\",\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_tokens\": 1000,\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\": \"get_player_stats\",\n",
    "            \"description\": \"Get detailed statistics for a specific player\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"player_name\": {\"type\": \"string\"},\n",
    "                    \"season\": {\"type\": \"integer\"}\n",
    "                },\n",
    "                \"required\": [\"player_name\"]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"get_team_stats\",\n",
    "            \"description\": \"Get team statistics and standings\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"team_name\": {\"type\": \"string\"},\n",
    "                    \"season\": {\"type\": \"integer\"}\n",
    "                },\n",
    "                \"required\": [\"team_name\"]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"get_match_result\",\n",
    "            \"description\": \"Get match result and box score\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"date\": {\"type\": \"string\"},\n",
    "                    \"teams\": {\"type\": \"array\"}\n",
    "                },\n",
    "                \"required\": [\"date\"]\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"include_sources\": True\n",
    "}\n",
    "\n",
    "print(\"Generator Configuration:\")\n",
    "print(json.dumps({k: v for k, v in GENERATOR_CONFIG.items() if k != 'functions'}, indent=2, ensure_ascii=False))\n",
    "print(f\"\\nFunction calling enabled: {len(GENERATOR_CONFIG['functions'])} functions available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c609127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement response generation\n",
    "# Example:\n",
    "# user_query = \"2024ë…„ ì‚¼ì„±ì˜ ìµœê³  íƒ€ìžëŠ” ëˆ„êµ¬?\"\n",
    "# \n",
    "# # Classify query\n",
    "# classification = classify_query(user_query)\n",
    "# \n",
    "# # Retrieve context\n",
    "# context_docs = hybrid_search(user_query, top_k=5)\n",
    "# \n",
    "# # Generate response\n",
    "# response = generate_response(\n",
    "#     query=user_query,\n",
    "#     context=context_docs,\n",
    "#     use_function_calling=True\n",
    "# )\n",
    "# \n",
    "# # Format final response\n",
    "# final_response = format_response(response, include_sources=True)\n",
    "# print(json.dumps(final_response, indent=2, ensure_ascii=False))\n",
    "\n",
    "print(\"[GENERATION STEP] - Ready to generate LLM responses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367c4dfd",
   "metadata": {},
   "source": [
    "## 8. End-to-End Pipeline Testing\n",
    "\n",
    "Test the complete pipeline with sample queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaf8ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete pipeline test queries\n",
    "pipeline_test_queries = [\n",
    "    \"2024 ì‹œì¦Œ í‰ê·  íƒ€ìœ¨ 0.300 ì´ìƒì¸ ì„ ìˆ˜ë“¤ì˜ ëª©ë¡ì„ ë³´ì—¬ì¤˜\",\n",
    "    \"ì‚¼ì„± ë¼ì´ì˜¨ì¦ˆì˜ 2024ë…„ í™ˆëŸ° í†µê³„ëŠ”?\",\n",
    "    \"ì§€ë‚œ ì£¼ë§ ê²½ê¸° ê²°ê³¼ë“¤ì„ ì •ë¦¬í•´ì¤„ëž˜?\",\n",
    "    \"2024ë…„ íˆ¬ìˆ˜ ë°©ì–´ìœ¨ í†µê³„ TOP 5ë¥¼ ì•Œë ¤ì¤˜\",\n",
    "    \"ìš°ë¦¬ íŒ€ì´ ì´ë²ˆ ì‹œì¦Œ ëª‡ ê²½ê¸°ë¥¼ ì´ê²¼ë‚˜ìš”?\"\n",
    "]\n",
    "\n",
    "print(\"End-to-End Pipeline Test Queries:\")\n",
    "for i, query in enumerate(pipeline_test_queries, 1):\n",
    "    print(f\"\\n{i}. {query}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1fdf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run complete pipeline tests\n",
    "# def run_complete_pipeline(user_query: str) -> Dict[str, Any]:\n",
    "#     \"\"\"Run the complete RAG pipeline for a user query.\"\"\"\n",
    "#     \n",
    "#     # Step 1: Classify query\n",
    "#     classification = classify_query(user_query)\n",
    "#     \n",
    "#     # Step 2: Retrieve relevant documents\n",
    "#     retrieved_docs = hybrid_search(user_query, top_k=5)\n",
    "#     \n",
    "#     # Step 3: Generate response\n",
    "#     response = generate_response(\n",
    "#         query=user_query,\n",
    "#         context=retrieved_docs,\n",
    "#         use_function_calling=True\n",
    "#     )\n",
    "#     \n",
    "#     return {\n",
    "#         \"query\": user_query,\n",
    "#         \"classification\": classification,\n",
    "#         \"retrieved_documents\": retrieved_docs,\n",
    "#         \"response\": response\n",
    "#     }\n",
    "# \n",
    "# # Run tests\n",
    "# test_results = []\n",
    "# for query in pipeline_test_queries:\n",
    "#     result = run_complete_pipeline(query)\n",
    "#     test_results.append(result)\n",
    "#     print(f\"\\n[TEST] Query: {query}\")\n",
    "#     print(f\"Classification: {result['classification']['intent']}\")\n",
    "#     print(f\"Response: {result['response'][:200]}...\")\n",
    "\n",
    "print(\"[PIPELINE TESTING] - Ready to test complete RAG system\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe08ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary and system status\n",
    "SYSTEM_STATUS = {\n",
    "    \"status\": \"Configuration Complete\",\n",
    "    \"components\": {\n",
    "        \"environment_setup\": \"âœ“ Completed\",\n",
    "        \"data_scraping\": \"â—‹ Ready to implement\",\n",
    "        \"data_processing\": \"â—‹ Ready to implement\",\n",
    "        \"vector_store\": \"â—‹ Ready to implement\",\n",
    "        \"query_classifier\": \"â—‹ Ready to implement\",\n",
    "        \"hybrid_retrieval\": \"â—‹ Ready to implement\",\n",
    "        \"response_generator\": \"â—‹ Ready to implement\",\n",
    "        \"pipeline_testing\": \"â—‹ Ready to implement\"\n",
    "    },\n",
    "    \"next_steps\": [\n",
    "        \"1. Implement scraping logic in src/scraper.py\",\n",
    "        \"2. Implement data processing in src/data_processor.py\",\n",
    "        \"3. Implement vector store in src/vector_store.py\",\n",
    "        \"4. Implement classifier in src/classifier.py\",\n",
    "        \"5. Implement retriever in src/retriever.py\",\n",
    "        \"6. Implement generator in src/generator.py\",\n",
    "        \"7. Execute and test complete pipeline\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"\\n=== SYSTEM STATUS ===\")\n",
    "print(json.dumps(SYSTEM_STATUS, indent=2, ensure_ascii=False))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
