{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e559a3d",
   "metadata": {},
   "source": [
    "# KBO ì•¼êµ¬ íŠ¹í™” ì±—ë´‡ \n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ ë…¼ë¬¸ \"A Chatbot for Football Analytics\" ì•„í‚¤í…ì²˜ë¥¼ KBO ì•¼êµ¬ì— ì ìš©í•œ ì±—ë´‡ì˜ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "## ì£¼ìš” êµ¬ì„± ìš”ì†Œ\n",
    "1. **ë°ì´í„° ì ì¬ (Ingest)**: JSON â†’ ChromaDB ë²¡í„° ì €ì¥ì†Œ\n",
    "2. **ì¿¼ë¦¬ ë¶„ë¥˜ (Classifier)**: general / season_analysis / match_analysis\n",
    "3. **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (Retriever)**: Semantic + BM25\n",
    "4. **ì‘ë‹µ ìƒì„± (Chain)**: LLM ê¸°ë°˜ ë¶„ì„\n",
    "5. **ì—ì´ì „íŠ¸ (Agent)**: Function Calling ì§€ì›\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9451a4e",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ\n",
    "\n",
    "í™˜ê²½ ë³€ìˆ˜ë¥¼ `.env` íŒŒì¼ì—ì„œ ë¡œë“œí•˜ê³ , API í‚¤ê°€ ì•ˆì „í•˜ê²Œ ê´€ë¦¬ë˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56cbed6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í”„ë¡œì íŠ¸ ë£¨íŠ¸: c:\\Coding\\PAINS-LLM\\PAINS-LLM\n",
      "âœ… OPENAI_API_KEY ë¡œë“œ: ì„±ê³µ âœ“\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# API í‚¤ í™•ì¸ (ê°’ì€ ì¶œë ¥í•˜ì§€ ì•ŠìŒ - ë³´ì•ˆ)\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(f\"âœ… í”„ë¡œì íŠ¸ ë£¨íŠ¸: {PROJECT_ROOT}\")\n",
    "print(f\"âœ… OPENAI_API_KEY ë¡œë“œ: {'ì„±ê³µ âœ“' if api_key else 'ì‹¤íŒ¨ âœ— (.env íŒŒì¼ í™•ì¸ í•„ìš”)'}\")\n",
    "\n",
    "if not api_key:\n",
    "    print(\"\\nâš ï¸ .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”:\")\n",
    "    print(\"   OPENAI_API_KEY=sk-your-api-key-here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8244469c",
   "metadata": {},
   "source": [
    "## 2. í”„ë¡œì íŠ¸ íŒŒì¼ êµ¬ì¡° ë¶„ì„\n",
    "\n",
    "í˜„ì¬ í”„ë¡œì íŠ¸ì˜ íŒŒì¼ êµ¬ì¡°ë¥¼ íŠ¸ë¦¬ í˜•íƒœë¡œ ì¶œë ¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46eef580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°:\n",
      "\n",
      "â”œâ”€â”€ data\n",
      "â”‚   â””â”€â”€ raw\n",
      "â”‚       â”œâ”€â”€ matches\n",
      "â”‚       â”‚   â”œâ”€â”€ 2024_postseason_game.json\n",
      "â”‚       â”‚   â”œâ”€â”€ 2024_regular_game.json\n",
      "â”‚       â”‚   â”œâ”€â”€ 2025_postseason_game_data.json\n",
      "â”‚       â”‚   â””â”€â”€ 2025_regular_game_data.json\n",
      "â”‚       â”œâ”€â”€ season_2024\n",
      "â”‚       â””â”€â”€ season_2025\n",
      "â”œâ”€â”€ src\n",
      "â”‚   â”œâ”€â”€ __init__.py\n",
      "â”‚   â”œâ”€â”€ agent.py\n",
      "â”‚   â”œâ”€â”€ chain.py\n",
      "â”‚   â”œâ”€â”€ classifier.py\n",
      "â”‚   â”œâ”€â”€ config.py\n",
      "â”‚   â”œâ”€â”€ ingest.py\n",
      "â”‚   â”œâ”€â”€ retriever.py\n",
      "â”‚   â”œâ”€â”€ tools.py\n",
      "â”‚   â””â”€â”€ utils.py\n",
      "â”œâ”€â”€ .env\n",
      "â”œâ”€â”€ .gitignore\n",
      "â”œâ”€â”€ A Chatbot for Football Analytics A deep dive into RAG, LLM Orchestration and Function Calling_extracted.txt\n",
      "â”œâ”€â”€ README.md\n",
      "â”œâ”€â”€ main.ipynb\n",
      "â”œâ”€â”€ main.py\n",
      "â””â”€â”€ requirements.txt\n"
     ]
    }
   ],
   "source": [
    "def print_tree(path: Path, prefix: str = \"\", ignore: set = None):\n",
    "    \"\"\"ë””ë ‰í† ë¦¬ êµ¬ì¡°ë¥¼ íŠ¸ë¦¬ í˜•íƒœë¡œ ì¶œë ¥\"\"\"\n",
    "    if ignore is None:\n",
    "        ignore = {'.git', '__pycache__', '.venv', 'node_modules', '.vscode', 'chroma_db'}\n",
    "    \n",
    "    items = sorted(path.iterdir(), key=lambda x: (x.is_file(), x.name))\n",
    "    items = [i for i in items if i.name not in ignore]\n",
    "    \n",
    "    for i, item in enumerate(items):\n",
    "        is_last = i == len(items) - 1\n",
    "        current_prefix = \"â””â”€â”€ \" if is_last else \"â”œâ”€â”€ \"\n",
    "        print(f\"{prefix}{current_prefix}{item.name}\")\n",
    "        \n",
    "        if item.is_dir():\n",
    "            next_prefix = \"    \" if is_last else \"â”‚   \"\n",
    "            print_tree(item, prefix + next_prefix, ignore)\n",
    "\n",
    "print(\"ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°:\\n\")\n",
    "print_tree(PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154cef62",
   "metadata": {},
   "source": [
    "## 3. í•µì‹¬ ëª¨ë“ˆ ì„í¬íŠ¸\n",
    "\n",
    "`src/` ë””ë ‰í† ë¦¬ì˜ í•µì‹¬ ëª¨ë“ˆë“¤ì„ ì„í¬íŠ¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cdd79d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ ì„¤ì • ì •ë³´:\n",
      "   - ì„ë² ë”© ëª¨ë¸: intfloat/multilingual-e5-large-instruct\n",
      "   - LLM ëª¨ë¸: gpt-4o\n",
      "   - ChromaDB ê²½ë¡œ: c:\\Coding\\PAINS-LLM\\PAINS-LLM\\data\\chroma_db\n",
      "   - ì»¬ë ‰ì…˜ ì´ë¦„: kbo_data\n",
      "   - ì‹œì¦Œ ë°ì´í„°: c:\\Coding\\PAINS-LLM\\PAINS-LLM\\data\\raw\\season_2025\n",
      "   - ê²½ê¸° ë°ì´í„°: c:\\Coding\\PAINS-LLM\\PAINS-LLM\\data\\raw\\matches\n",
      "   - Top-K ê²€ìƒ‰: 5\n"
     ]
    }
   ],
   "source": [
    "# í•µì‹¬ ëª¨ë“ˆ ì„í¬íŠ¸\n",
    "from src.config import (\n",
    "    CHROMA_DB_DIR, COLLECTION_NAME, EMBEDDING_MODEL,\n",
    "    SEASON_DATA_DIR, MATCH_DATA_DIR, LLM_MODEL, RETRIEVAL_TOP_K\n",
    ")\n",
    "\n",
    "print(\"ğŸ“¦ ì„¤ì • ì •ë³´:\")\n",
    "print(f\"   - ì„ë² ë”© ëª¨ë¸: {EMBEDDING_MODEL}\")\n",
    "print(f\"   - LLM ëª¨ë¸: {LLM_MODEL}\")\n",
    "print(f\"   - ChromaDB ê²½ë¡œ: {CHROMA_DB_DIR}\")\n",
    "print(f\"   - ì»¬ë ‰ì…˜ ì´ë¦„: {COLLECTION_NAME}\")\n",
    "print(f\"   - ì‹œì¦Œ ë°ì´í„°: {SEASON_DATA_DIR}\")\n",
    "print(f\"   - ê²½ê¸° ë°ì´í„°: {MATCH_DATA_DIR}\")\n",
    "print(f\"   - Top-K ê²€ìƒ‰: {RETRIEVAL_TOP_K}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6332ebcc",
   "metadata": {},
   "source": [
    "## 4. ë°ì´í„° ì ì¬ (Ingest)\n",
    "\n",
    "JSON ë°ì´í„°ë¥¼ ChromaDB ë²¡í„° ì €ì¥ì†Œì— ì ì¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "### í•µì‹¬ ì „ëµ (ë…¼ë¬¸ Section 4.2)\n",
    "- JSONì„ ê·¸ëŒ€ë¡œ ì„ë² ë”©í•˜ì§€ ì•ŠìŒ\n",
    "- **ì„œìˆ í˜• ë¬¸ì¥(Descriptive Sentence)** ì„ ìƒì„±í•˜ì—¬ ì„ë² ë”©\n",
    "- ì›ë³¸ ë°ì´í„°ëŠ” metadataì— ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8de0d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸš€ KBO ë°ì´í„° ì ì¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘\n",
      "============================================================\n",
      "\n",
      "ğŸ“¥ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "ğŸ“‚ ì‹œì¦Œ ë°ì´í„° íŒŒì¼ ë°œê²¬: 0ê°œ\n",
      "ğŸ“‚ ê²½ê¸° ë°ì´í„° íŒŒì¼ ë°œê²¬: 4ê°œ\n",
      "   - 2024_postseason_game.json: 183ê°œ ë ˆì½”ë“œ ë°œê²¬\n",
      "   - 2024_regular_game.json: 7115ê°œ ë ˆì½”ë“œ ë°œê²¬\n",
      "   - 2025_postseason_game_data.json: 178ê°œ ë ˆì½”ë“œ ë°œê²¬\n",
      "   - 2025_regular_game_data.json: 8089ê°œ ë ˆì½”ë“œ ë°œê²¬\n",
      "\n",
      "ğŸ“Š ë¡œë“œëœ ë°ì´í„° ìš”ì•½:\n",
      "   - ì‹œì¦Œ ë°ì´í„°: 0ê±´\n",
      "   - ê²½ê¸° ë°ì´í„°: 15565ê±´\n",
      "\n",
      "ğŸ”„ ì‹œì¦Œ ë°ì´í„° ë³€í™˜ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Season: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ ê²½ê¸° ë°ì´í„° ë³€í™˜ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Match: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15565/15565 [00:00<00:00, 73098.01it/s]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Coding\\PAINS-LLM\\PAINS-LLM\\.venv\\Lib\\site-packages\\langchain_community\\embeddings\\huggingface.py:84\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Coding\\PAINS-LLM\\PAINS-LLM\\.venv\\Lib\\site-packages\\sentence_transformers\\__init__.py:15\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     11\u001b[39m     export_dynamic_quantized_onnx_model,\n\u001b[32m     12\u001b[39m     export_optimized_onnx_model,\n\u001b[32m     13\u001b[39m     export_static_quantized_openvino_model,\n\u001b[32m     14\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcross_encoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     CrossEncoder,\n\u001b[32m     17\u001b[39m     CrossEncoderModelCardData,\n\u001b[32m     18\u001b[39m     CrossEncoderTrainer,\n\u001b[32m     19\u001b[39m     CrossEncoderTrainingArguments,\n\u001b[32m     20\u001b[39m )\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Coding\\PAINS-LLM\\PAINS-LLM\\.venv\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mCrossEncoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_card\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderModelCardData\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Coding\\PAINS-LLM\\PAINS-LLM\\.venv\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:21\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautonotebook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m trange\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     22\u001b[39m     AutoConfig,\n\u001b[32m     23\u001b[39m     AutoModelForSequenceClassification,\n\u001b[32m     24\u001b[39m     AutoTokenizer,\n\u001b[32m     25\u001b[39m     PretrainedConfig,\n\u001b[32m     26\u001b[39m     PreTrainedModel,\n\u001b[32m     27\u001b[39m     PreTrainedTokenizer,\n\u001b[32m     28\u001b[39m     is_torch_npu_available,\n\u001b[32m     29\u001b[39m )\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PushToHubMixin\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'PreTrainedModel' from 'transformers' (c:\\Coding\\PAINS-LLM\\PAINS-LLM\\.venv\\Lib\\site-packages\\transformers\\__init__.py)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mingest\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ingest_all_data, initialize_vector_store\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# ë°ì´í„° ì ì¬ ì‹¤í–‰\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# clear_existing=True: ê¸°ì¡´ DB ì‚­ì œ í›„ ì¬ì ì¬\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m result = \u001b[43mingest_all_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclear_existing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[32m      8\u001b[39m     doc_count = result._collection.count()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Coding\\PAINS-LLM\\PAINS-LLM\\src\\ingest.py:424\u001b[39m, in \u001b[36mingest_all_data\u001b[39m\u001b[34m(season_dir, match_dir, clear_existing)\u001b[39m\n\u001b[32m    421\u001b[39m documents = prepare_documents(season_data, match_data)\n\u001b[32m    423\u001b[39m \u001b[38;5;66;03m# 4. ChromaDB ì ì¬\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m vector_store = \u001b[43minitialize_vector_store\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[38;5;66;03m# 5. ê²°ê³¼ í™•ì¸\u001b[39;00m\n\u001b[32m    427\u001b[39m doc_count = vector_store._collection.count()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Coding\\PAINS-LLM\\PAINS-LLM\\src\\ingest.py:324\u001b[39m, in \u001b[36minitialize_vector_store\u001b[39m\u001b[34m(documents, persist_directory, collection_name)\u001b[39m\n\u001b[32m    321\u001b[39m     collection_name = COLLECTION_NAME\n\u001b[32m    323\u001b[39m \u001b[38;5;66;03m# ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m embeddings = \u001b[43mget_embedding_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m documents:\n\u001b[32m    327\u001b[39m     \u001b[38;5;66;03m# ìƒˆë¡œìš´ ë¬¸ì„œë¡œ ë²¡í„° ìŠ¤í† ì–´ ìƒì„±\u001b[39;00m\n\u001b[32m    328\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mğŸ“¦ ChromaDB ì´ˆê¸°í™” ì¤‘... (ë¬¸ì„œ ìˆ˜: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(documents)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Coding\\PAINS-LLM\\PAINS-LLM\\src\\ingest.py:48\u001b[39m, in \u001b[36mget_embedding_model\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_embedding_model\u001b[39m() -> HuggingFaceEmbeddings:\n\u001b[32m     39\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[33;03m    ì„ë² ë”© ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[33;03m    \u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     46\u001b[39m \u001b[33;03m        HuggingFaceEmbeddings: ì´ˆê¸°í™”ëœ ì„ë² ë”© ëª¨ë¸\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHuggingFaceEmbeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEMBEDDING_MODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdevice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# GPU ì—†ëŠ” í™˜ê²½ ì§€ì›\u001b[39;49;00m\n\u001b[32m     51\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencode_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnormalize_embeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# L2 ì •ê·œí™” - ë…¼ë¬¸ ê¶Œì¥\u001b[39;49;00m\n\u001b[32m     53\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Coding\\PAINS-LLM\\PAINS-LLM\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:239\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    237\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    238\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Coding\\PAINS-LLM\\PAINS-LLM\\.venv\\Lib\\site-packages\\langchain_community\\embeddings\\huggingface.py:87\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     88\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not import sentence_transformers python package. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     89\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease install it with `pip install sentence-transformers`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     90\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[38;5;28mself\u001b[39m.client = sentence_transformers.SentenceTransformer(\n\u001b[32m     93\u001b[39m     \u001b[38;5;28mself\u001b[39m.model_name, cache_folder=\u001b[38;5;28mself\u001b[39m.cache_folder, **\u001b[38;5;28mself\u001b[39m.model_kwargs\n\u001b[32m     94\u001b[39m )\n",
      "\u001b[31mImportError\u001b[39m: Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`."
     ]
    }
   ],
   "source": [
    "from src.ingest import ingest_all_data, initialize_vector_store\n",
    "\n",
    "# ë°ì´í„° ì ì¬ ì‹¤í–‰\n",
    "# clear_existing=True: ê¸°ì¡´ DB ì‚­ì œ í›„ ì¬ì ì¬\n",
    "result = ingest_all_data(clear_existing=True)\n",
    "\n",
    "if result:\n",
    "    doc_count = result._collection.count()\n",
    "    print(f\"\\nğŸ‰ ë²¡í„° ìŠ¤í† ì–´ ì¤€ë¹„ ì™„ë£Œ! ë¬¸ì„œ ìˆ˜: {doc_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf55e26",
   "metadata": {},
   "source": [
    "## 5. ì¿¼ë¦¬ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸ (Classifier)\n",
    "\n",
    "ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ `general`, `season_analysis`, `match_analysis` ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb88c201",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.classifier import classify_query\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤\n",
    "test_queries = [\n",
    "    \"ì•¼êµ¬ ê·œì¹™ ì„¤ëª…í•´ì¤˜\",              # general\n",
    "    \"í•œí™” ì´ê¸€ìŠ¤ ì˜¬ì‹œì¦Œ ì„±ì  ë¶„ì„í•´ì¤˜\",   # season_analysis\n",
    "    \"ì–´ì œ í•œí™” LG ê²½ê¸° ì–´ë• ì–´?\",        # match_analysis\n",
    "]\n",
    "\n",
    "print(\"ğŸ” ì¿¼ë¦¬ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸:\\n\")\n",
    "for query in test_queries:\n",
    "    result = classify_query(query)\n",
    "    print(f\"ì¿¼ë¦¬: {query}\")\n",
    "    print(f\"  â†’ ë¶„ë¥˜: {result.query_type}\")\n",
    "    print(f\"  â†’ íŒ€: {result.teams}\")\n",
    "    print(f\"  â†’ ì‹ ë¢°ë„: {result.confidence:.0%}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810267cc",
   "metadata": {},
   "source": [
    "## 6. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ (Retriever)\n",
    "\n",
    "Semantic Search + BM25ë¥¼ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54df9189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.retriever import retrieve_for_query\n",
    "\n",
    "# ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "test_query = \"í•œí™” ì´ê¸€ìŠ¤ ì‹œì¦Œ ì„±ì \"\n",
    "\n",
    "print(f\"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: '{test_query}'\\n\")\n",
    "results = retrieve_for_query(test_query, top_k=3)\n",
    "\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"ê²°ê³¼ {i}:\")\n",
    "    print(f\"  íƒ€ì…: {doc.metadata.get('type')}\")\n",
    "    print(f\"  íŒ€: {doc.metadata.get('teams', doc.metadata.get('team'))}\")\n",
    "    print(f\"  ë‚´ìš©: {doc.page_content[:100]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0263fb",
   "metadata": {},
   "source": [
    "## 7. ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (Chain)\n",
    "\n",
    "ë¶„ë¥˜ â†’ ê²€ìƒ‰ â†’ ìƒì„±ì˜ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f455cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.chain import run_analysis\n",
    "\n",
    "# ë¶„ì„ ì‹¤í–‰\n",
    "query = \"í•œí™” ì´ê¸€ìŠ¤ ì˜¬ì‹œì¦Œ ì„±ì  ë¶„ì„í•´ì¤˜\"\n",
    "print(f\"ğŸ’¬ ì§ˆë¬¸: {query}\\n\")\n",
    "\n",
    "result = run_analysis(query)\n",
    "\n",
    "print(f\"ğŸ“Š ë¶„ë¥˜: {result.query_type}\")\n",
    "print(f\"ğŸ“Š íŒ€: {result.teams}\")\n",
    "print(f\"ğŸ“Š ê²€ìƒ‰ ì ìˆ˜: {result.retrieval_score:.2%}\")\n",
    "print(f\"ğŸ“Š ëŒ€ì‹œë³´ë“œ í•„ìš”: {result.needs_dashboard}\")\n",
    "print(f\"\\nğŸ¤– ì‘ë‹µ:\\n{result.response[:500]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f288824f",
   "metadata": {},
   "source": [
    "## 8. ëŒ€í™”í˜• ì—ì´ì „íŠ¸ (Agent)\n",
    "\n",
    "Function Callingì„ ì§€ì›í•˜ëŠ” ëŒ€í™”í˜• ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7430c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agent import chat\n",
    "\n",
    "# ì—ì´ì „íŠ¸ ëŒ€í™” í…ŒìŠ¤íŠ¸\n",
    "queries = [\n",
    "    \"ì•ˆë…•! KBOì— ëŒ€í•´ ì•Œë ¤ì¤˜\",\n",
    "    \"í•œí™” ì´ê¸€ìŠ¤ ì˜¬ì‹œì¦Œ ì„±ì  ë¶„ì„í•´ì¤˜\",\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    print(f\"ğŸ‘¤ User: {q}\")\n",
    "    response = chat(q)\n",
    "    print(f\"ğŸ¤– Assistant: {response.response[:300]}...\")\n",
    "    if response.dashboard:\n",
    "        print(f\"   ğŸ“Š ëŒ€ì‹œë³´ë“œ ìƒì„±ë¨!\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb35289",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ ë…¼ë¬¸ ëŒ€ë¹„ êµ¬í˜„ ì°¨ì´ì  ë° ChromaDB êµ¬ì„±\n",
    "\n",
    "### ë…¼ë¬¸ê³¼ ë™ì¼í•˜ê²Œ êµ¬í˜„í•œ ë¶€ë¶„\n",
    "| ë…¼ë¬¸ ì„¹ì…˜ | êµ¬í˜„ ë‚´ìš© |\n",
    "|----------|----------|\n",
    "| Section 4.2 (Embedding) | `multilingual-e5-large-instruct` ëª¨ë¸ ì‚¬ìš©, L2 ì •ê·œí™” |\n",
    "| Section 4.3.1 (Query Classification) | CoT í”„ë¡¬í”„íŒ…ìœ¼ë¡œ general/season/match ë¶„ë¥˜ |\n",
    "| Section 4.3.2 (Query Normalization) | RapidFuzz QRatio ìŠ¤ì½”ëŸ¬ë¡œ íŒ€ëª… í¼ì§€ ë§¤ì¹­ |\n",
    "| Section 4.4.1 (Instruct Format) | `\"Instruct: ... Query: ...\"` í¬ë§· ì‚¬ìš© |\n",
    "| Section 4.4.2 (Hybrid Retrieval) | Semantic (0.8) + BM25 (0.2) ì•™ìƒë¸” |\n",
    "| Section 4.5.4 (Function Calling) | ëŒ€ì‹œë³´ë“œ ìƒì„±ìš© ë„êµ¬ ì •ì˜ |\n",
    "\n",
    "### ë…¼ë¬¸ê³¼ ë‹¤ë¥´ê²Œ (KBOì— ë§ê²Œ) ìˆ˜ì •í•œ ë¶€ë¶„\n",
    "\n",
    "| í•­ëª© | ë…¼ë¬¸ (ì¶•êµ¬) | ì´ í”„ë¡œì íŠ¸ (ì•¼êµ¬) |\n",
    "|-----|-----------|------------------|\n",
    "| **ë„ë©”ì¸** | ìœ ëŸ½ ì¶•êµ¬ ë¦¬ê·¸ | KBO í•œêµ­ í”„ë¡œì•¼êµ¬ |\n",
    "| **TEAM_MAP** | ì¶•êµ¬íŒ€ + ëŒ€íšŒ ë§¤í•‘ | 10ê°œ KBO íŒ€ + í•œê¸€ ë³„ì¹­ |\n",
    "| **ë°ì´í„° êµ¬ì¡°** | ë¦¬ê·¸/ê²½ê¸° JSON | ì‹œì¦Œ/ê²½ê¸° JSON (ì•¼êµ¬ ìŠ¤íƒ¯) |\n",
    "| **KPI** | xG, íŒ¨ìŠ¤ ë“± | íƒ€ìœ¨, ë°©ì–´ìœ¨, OPS ë“± |\n",
    "| **Instruct í”„ë¡¬í”„íŠ¸** | \"football dataset\" | \"baseball dataset\" |\n",
    "\n",
    "### ChromaDB ë²¡í„° ì €ì¥ì†Œ êµ¬ì„±\n",
    "\n",
    "```\n",
    "data/\n",
    "â””â”€â”€ chroma_db/           â† ë…¼ë¬¸ê³¼ ë™ì¼í•˜ê²Œ ë¡œì»¬ ì˜êµ¬ ì €ì¥ì†Œ ì‚¬ìš©\n",
    "    â”œâ”€â”€ chroma.sqlite3   â† ë©”íƒ€ë°ì´í„° ì €ì¥\n",
    "    â””â”€â”€ [UUID í´ë”ë“¤]/   â† ë²¡í„° ì„ë² ë”© ì €ì¥\n",
    "```\n",
    "\n",
    "- **ì €ì¥ ìœ„ì¹˜**: `data/chroma_db/` (config.pyì˜ `CHROMA_DB_DIR`)\n",
    "- **ì»¬ë ‰ì…˜ ì´ë¦„**: `kbo_data` (config.pyì˜ `COLLECTION_NAME`)\n",
    "- **ì„ë² ë”© ì°¨ì›**: 1024 (multilingual-e5-large-instruct)\n",
    "- **ì¸ë±ìŠ¤ ë°©ì‹**: HNSW (ChromaDB ê¸°ë³¸ê°’)\n",
    "\n",
    "> ğŸ’¡ ë…¼ë¬¸ì—ì„œëŠ” PlaymakerAI APIì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™”ì§€ë§Œ, ì´ í”„ë¡œì íŠ¸ëŠ” ë¡œì»¬ JSON íŒŒì¼ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "> ì´ëŠ” API ì—†ì´ë„ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆë„ë¡ í•œ ì„¤ê³„ ê²°ì •ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f3bbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChromaDB ìƒíƒœ í™•ì¸\n",
    "from src.ingest import initialize_vector_store\n",
    "\n",
    "vector_store = initialize_vector_store(documents=None)  # ê¸°ì¡´ ìŠ¤í† ì–´ ë¡œë“œ\n",
    "collection = vector_store._collection\n",
    "\n",
    "print(\"ğŸ—„ï¸ ChromaDB ë²¡í„° ì €ì¥ì†Œ ì •ë³´:\")\n",
    "print(f\"   - ì €ì¥ ê²½ë¡œ: {CHROMA_DB_DIR}\")\n",
    "print(f\"   - ì»¬ë ‰ì…˜ ì´ë¦„: {collection.name}\")\n",
    "print(f\"   - ë¬¸ì„œ ìˆ˜: {collection.count()}\")\n",
    "print(f\"   - ì„ë² ë”© ëª¨ë¸: {EMBEDDING_MODEL}\")\n",
    "print(f\"   - ì„ë² ë”© ì°¨ì›: 1024 (multilingual-e5-large-instruct)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
